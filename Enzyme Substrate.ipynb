{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca95ffdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fec5babb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "df_samp = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f721d1ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>BertzCT</th>\n",
       "      <th>Chi1</th>\n",
       "      <th>Chi1n</th>\n",
       "      <th>Chi1v</th>\n",
       "      <th>Chi2n</th>\n",
       "      <th>Chi2v</th>\n",
       "      <th>Chi3v</th>\n",
       "      <th>Chi4n</th>\n",
       "      <th>EState_VSA1</th>\n",
       "      <th>...</th>\n",
       "      <th>SlogP_VSA3</th>\n",
       "      <th>VSA_EState9</th>\n",
       "      <th>fr_COO</th>\n",
       "      <th>fr_COO2</th>\n",
       "      <th>EC1</th>\n",
       "      <th>EC2</th>\n",
       "      <th>EC3</th>\n",
       "      <th>EC4</th>\n",
       "      <th>EC5</th>\n",
       "      <th>EC6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>323.390782</td>\n",
       "      <td>9.879918</td>\n",
       "      <td>5.875576</td>\n",
       "      <td>5.875576</td>\n",
       "      <td>4.304757</td>\n",
       "      <td>4.304757</td>\n",
       "      <td>2.754513</td>\n",
       "      <td>1.749203</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.794537</td>\n",
       "      <td>35.527357</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>273.723798</td>\n",
       "      <td>7.259037</td>\n",
       "      <td>4.441467</td>\n",
       "      <td>5.834958</td>\n",
       "      <td>3.285046</td>\n",
       "      <td>4.485235</td>\n",
       "      <td>2.201375</td>\n",
       "      <td>1.289775</td>\n",
       "      <td>45.135471</td>\n",
       "      <td>...</td>\n",
       "      <td>13.825658</td>\n",
       "      <td>44.707310</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>521.643822</td>\n",
       "      <td>10.911303</td>\n",
       "      <td>8.527859</td>\n",
       "      <td>11.050864</td>\n",
       "      <td>6.665291</td>\n",
       "      <td>9.519706</td>\n",
       "      <td>5.824822</td>\n",
       "      <td>1.770579</td>\n",
       "      <td>15.645394</td>\n",
       "      <td>...</td>\n",
       "      <td>17.964475</td>\n",
       "      <td>45.660120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>567.431166</td>\n",
       "      <td>12.453343</td>\n",
       "      <td>7.089119</td>\n",
       "      <td>12.833709</td>\n",
       "      <td>6.478023</td>\n",
       "      <td>10.978151</td>\n",
       "      <td>7.914542</td>\n",
       "      <td>3.067181</td>\n",
       "      <td>95.639554</td>\n",
       "      <td>...</td>\n",
       "      <td>31.961948</td>\n",
       "      <td>87.509997</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>112.770735</td>\n",
       "      <td>4.414719</td>\n",
       "      <td>2.866236</td>\n",
       "      <td>2.866236</td>\n",
       "      <td>1.875634</td>\n",
       "      <td>1.875634</td>\n",
       "      <td>1.036450</td>\n",
       "      <td>0.727664</td>\n",
       "      <td>17.980451</td>\n",
       "      <td>...</td>\n",
       "      <td>9.589074</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     BertzCT       Chi1     Chi1n      Chi1v     Chi2n      Chi2v  \\\n",
       "0   0  323.390782   9.879918  5.875576   5.875576  4.304757   4.304757   \n",
       "1   1  273.723798   7.259037  4.441467   5.834958  3.285046   4.485235   \n",
       "2   2  521.643822  10.911303  8.527859  11.050864  6.665291   9.519706   \n",
       "3   3  567.431166  12.453343  7.089119  12.833709  6.478023  10.978151   \n",
       "4   4  112.770735   4.414719  2.866236   2.866236  1.875634   1.875634   \n",
       "\n",
       "      Chi3v     Chi4n  EState_VSA1  ...  SlogP_VSA3  VSA_EState9  fr_COO  \\\n",
       "0  2.754513  1.749203     0.000000  ...    4.794537    35.527357       0   \n",
       "1  2.201375  1.289775    45.135471  ...   13.825658    44.707310       0   \n",
       "2  5.824822  1.770579    15.645394  ...   17.964475    45.660120       0   \n",
       "3  7.914542  3.067181    95.639554  ...   31.961948    87.509997       0   \n",
       "4  1.036450  0.727664    17.980451  ...    9.589074    33.333333       2   \n",
       "\n",
       "   fr_COO2  EC1  EC2  EC3  EC4  EC5  EC6  \n",
       "0        0    1    1    0    0    0    0  \n",
       "1        0    0    1    1    0    0    0  \n",
       "2        0    1    1    0    0    1    0  \n",
       "3        0    1    1    0    0    0    0  \n",
       "4        2    1    0    1    1    1    0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6c07086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>BertzCT</th>\n",
       "      <th>Chi1</th>\n",
       "      <th>Chi1n</th>\n",
       "      <th>Chi1v</th>\n",
       "      <th>Chi2n</th>\n",
       "      <th>Chi2v</th>\n",
       "      <th>Chi3v</th>\n",
       "      <th>Chi4n</th>\n",
       "      <th>EState_VSA1</th>\n",
       "      <th>...</th>\n",
       "      <th>PEOE_VSA14</th>\n",
       "      <th>PEOE_VSA6</th>\n",
       "      <th>PEOE_VSA7</th>\n",
       "      <th>PEOE_VSA8</th>\n",
       "      <th>SMR_VSA10</th>\n",
       "      <th>SMR_VSA5</th>\n",
       "      <th>SlogP_VSA3</th>\n",
       "      <th>VSA_EState9</th>\n",
       "      <th>fr_COO</th>\n",
       "      <th>fr_COO2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14838</td>\n",
       "      <td>344.632371</td>\n",
       "      <td>7.283603</td>\n",
       "      <td>4.473966</td>\n",
       "      <td>5.834958</td>\n",
       "      <td>3.412257</td>\n",
       "      <td>4.651530</td>\n",
       "      <td>2.096558</td>\n",
       "      <td>1.116433</td>\n",
       "      <td>49.458581</td>\n",
       "      <td>...</td>\n",
       "      <td>13.512441</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.809272</td>\n",
       "      <td>24.539800</td>\n",
       "      <td>4.794537</td>\n",
       "      <td>47.304082</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14839</td>\n",
       "      <td>1432.410201</td>\n",
       "      <td>10.663869</td>\n",
       "      <td>7.079026</td>\n",
       "      <td>8.065215</td>\n",
       "      <td>5.297097</td>\n",
       "      <td>5.297097</td>\n",
       "      <td>3.924155</td>\n",
       "      <td>2.569694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.947374</td>\n",
       "      <td>98.323987</td>\n",
       "      <td>9.606882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>53.378235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14840</td>\n",
       "      <td>83.352608</td>\n",
       "      <td>3.931852</td>\n",
       "      <td>1.774215</td>\n",
       "      <td>1.774215</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>0.467830</td>\n",
       "      <td>0.170838</td>\n",
       "      <td>5.969305</td>\n",
       "      <td>...</td>\n",
       "      <td>5.969305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.420822</td>\n",
       "      <td>11.752550</td>\n",
       "      <td>13.344559</td>\n",
       "      <td>9.589074</td>\n",
       "      <td>24.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14841</td>\n",
       "      <td>150.255712</td>\n",
       "      <td>5.912790</td>\n",
       "      <td>3.548812</td>\n",
       "      <td>3.548812</td>\n",
       "      <td>2.595128</td>\n",
       "      <td>2.595128</td>\n",
       "      <td>1.642813</td>\n",
       "      <td>0.694113</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>59.935299</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.744066</td>\n",
       "      <td>32.290168</td>\n",
       "      <td>4.794537</td>\n",
       "      <td>26.778866</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14842</td>\n",
       "      <td>1817.276351</td>\n",
       "      <td>24.910940</td>\n",
       "      <td>15.540529</td>\n",
       "      <td>20.047314</td>\n",
       "      <td>12.535886</td>\n",
       "      <td>17.730988</td>\n",
       "      <td>11.979618</td>\n",
       "      <td>4.431173</td>\n",
       "      <td>84.554972</td>\n",
       "      <td>...</td>\n",
       "      <td>23.468091</td>\n",
       "      <td>25.609359</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.099000</td>\n",
       "      <td>69.141353</td>\n",
       "      <td>38.704130</td>\n",
       "      <td>50.697492</td>\n",
       "      <td>102.583333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id      BertzCT       Chi1      Chi1n      Chi1v      Chi2n      Chi2v  \\\n",
       "0  14838   344.632371   7.283603   4.473966   5.834958   3.412257   4.651530   \n",
       "1  14839  1432.410201  10.663869   7.079026   8.065215   5.297097   5.297097   \n",
       "2  14840    83.352608   3.931852   1.774215   1.774215   1.073446   1.073446   \n",
       "3  14841   150.255712   5.912790   3.548812   3.548812   2.595128   2.595128   \n",
       "4  14842  1817.276351  24.910940  15.540529  20.047314  12.535886  17.730988   \n",
       "\n",
       "       Chi3v     Chi4n  EState_VSA1  ...  PEOE_VSA14  PEOE_VSA6  PEOE_VSA7  \\\n",
       "0   2.096558  1.116433    49.458581  ...   13.512441   0.000000   0.000000   \n",
       "1   3.924155  2.569694     0.000000  ...    0.000000  34.947374  98.323987   \n",
       "2   0.467830  0.170838     5.969305  ...    5.969305   0.000000   0.000000   \n",
       "3   1.642813  0.694113     0.000000  ...   59.935299   0.000000   0.000000   \n",
       "4  11.979618  4.431173    84.554972  ...   23.468091  25.609359   0.000000   \n",
       "\n",
       "   PEOE_VSA8  SMR_VSA10   SMR_VSA5  SlogP_VSA3  VSA_EState9  fr_COO  fr_COO2  \n",
       "0   0.000000  26.809272  24.539800    4.794537    47.304082       1        1  \n",
       "1   9.606882   0.000000  53.378235    0.000000    43.166667       0        0  \n",
       "2   6.420822  11.752550  13.344559    9.589074    24.666667       1        1  \n",
       "3   0.000000  17.744066  32.290168    4.794537    26.778866       0        0  \n",
       "4  37.099000  69.141353  38.704130   50.697492   102.583333       0        0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b05cfa3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>EC1</th>\n",
       "      <th>EC2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14838</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14839</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14840</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14841</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14842</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  EC1  EC2\n",
       "0  14838  0.5  0.5\n",
       "1  14839  0.5  0.5\n",
       "2  14840  0.5  0.5\n",
       "3  14841  0.5  0.5\n",
       "4  14842  0.5  0.5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_samp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76c84a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(['id', 'EC1', 'EC2', 'EC3', 'EC4', 'EC5', 'EC6'], axis=1)\n",
    "Y_train = df_train.iloc[:, 32:34]\n",
    "EC1_train = Y_train['EC1']\n",
    "EC2_train = Y_train['EC2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31c15586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14838 entries, 0 to 14837\n",
      "Data columns (total 31 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   BertzCT            14838 non-null  float64\n",
      " 1   Chi1               14838 non-null  float64\n",
      " 2   Chi1n              14838 non-null  float64\n",
      " 3   Chi1v              14838 non-null  float64\n",
      " 4   Chi2n              14838 non-null  float64\n",
      " 5   Chi2v              14838 non-null  float64\n",
      " 6   Chi3v              14838 non-null  float64\n",
      " 7   Chi4n              14838 non-null  float64\n",
      " 8   EState_VSA1        14838 non-null  float64\n",
      " 9   EState_VSA2        14838 non-null  float64\n",
      " 10  ExactMolWt         14838 non-null  float64\n",
      " 11  FpDensityMorgan1   14838 non-null  float64\n",
      " 12  FpDensityMorgan2   14838 non-null  float64\n",
      " 13  FpDensityMorgan3   14838 non-null  float64\n",
      " 14  HallKierAlpha      14838 non-null  float64\n",
      " 15  HeavyAtomMolWt     14838 non-null  float64\n",
      " 16  Kappa3             14838 non-null  float64\n",
      " 17  MaxAbsEStateIndex  14838 non-null  float64\n",
      " 18  MinEStateIndex     14838 non-null  float64\n",
      " 19  NumHeteroatoms     14838 non-null  int64  \n",
      " 20  PEOE_VSA10         14838 non-null  float64\n",
      " 21  PEOE_VSA14         14838 non-null  float64\n",
      " 22  PEOE_VSA6          14838 non-null  float64\n",
      " 23  PEOE_VSA7          14838 non-null  float64\n",
      " 24  PEOE_VSA8          14838 non-null  float64\n",
      " 25  SMR_VSA10          14838 non-null  float64\n",
      " 26  SMR_VSA5           14838 non-null  float64\n",
      " 27  SlogP_VSA3         14838 non-null  float64\n",
      " 28  VSA_EState9        14838 non-null  float64\n",
      " 29  fr_COO             14838 non-null  int64  \n",
      " 30  fr_COO2            14838 non-null  int64  \n",
      "dtypes: float64(28), int64(3)\n",
      "memory usage: 3.5 MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6696b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "960dc964",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv1D, MaxPooling1D, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09e57fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(31,), activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model1 = model2 = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cdf7fc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1336/1336 [==============================] - 1s 567us/step - loss: 0.6676 - accuracy: 0.6670 - val_loss: 0.6421 - val_accuracy: 0.6664\n",
      "Epoch 2/100\n",
      "1336/1336 [==============================] - 1s 516us/step - loss: 0.6181 - accuracy: 0.6679 - val_loss: 0.6321 - val_accuracy: 0.6664\n",
      "Epoch 3/100\n",
      "1336/1336 [==============================] - 1s 515us/step - loss: 0.6125 - accuracy: 0.6678 - val_loss: 0.6206 - val_accuracy: 0.6664\n",
      "Epoch 4/100\n",
      "1336/1336 [==============================] - 1s 513us/step - loss: 0.6101 - accuracy: 0.6679 - val_loss: 0.6184 - val_accuracy: 0.6664\n",
      "Epoch 5/100\n",
      "1336/1336 [==============================] - 1s 519us/step - loss: 0.6071 - accuracy: 0.6679 - val_loss: 0.6217 - val_accuracy: 0.6664\n",
      "Epoch 6/100\n",
      "1336/1336 [==============================] - 1s 532us/step - loss: 0.6058 - accuracy: 0.6681 - val_loss: 0.6326 - val_accuracy: 0.6671\n",
      "Epoch 7/100\n",
      "1336/1336 [==============================] - 1s 512us/step - loss: 0.6042 - accuracy: 0.6678 - val_loss: 0.6259 - val_accuracy: 0.6664\n",
      "Epoch 8/100\n",
      "1336/1336 [==============================] - 1s 520us/step - loss: 0.6023 - accuracy: 0.6679 - val_loss: 0.6173 - val_accuracy: 0.6664\n",
      "Epoch 9/100\n",
      "1336/1336 [==============================] - 1s 515us/step - loss: 0.6035 - accuracy: 0.6679 - val_loss: 0.6947 - val_accuracy: 0.6637\n",
      "Epoch 10/100\n",
      "1336/1336 [==============================] - 1s 514us/step - loss: 0.6043 - accuracy: 0.6677 - val_loss: 0.6208 - val_accuracy: 0.6664\n",
      "Epoch 11/100\n",
      "1336/1336 [==============================] - 1s 522us/step - loss: 0.5977 - accuracy: 0.6679 - val_loss: 0.6174 - val_accuracy: 0.6664\n",
      "Epoch 12/100\n",
      "1336/1336 [==============================] - 1s 526us/step - loss: 0.5997 - accuracy: 0.6679 - val_loss: 0.6159 - val_accuracy: 0.6664\n",
      "Epoch 13/100\n",
      "1336/1336 [==============================] - 1s 527us/step - loss: 0.5989 - accuracy: 0.6675 - val_loss: 0.6178 - val_accuracy: 0.6664\n",
      "Epoch 14/100\n",
      "1336/1336 [==============================] - 1s 511us/step - loss: 0.5966 - accuracy: 0.6679 - val_loss: 0.6192 - val_accuracy: 0.6664\n",
      "Epoch 15/100\n",
      "1336/1336 [==============================] - 1s 517us/step - loss: 0.5968 - accuracy: 0.6679 - val_loss: 0.6142 - val_accuracy: 0.6664\n",
      "Epoch 16/100\n",
      "1336/1336 [==============================] - 1s 518us/step - loss: 0.5964 - accuracy: 0.6679 - val_loss: 0.6370 - val_accuracy: 0.6664\n",
      "Epoch 17/100\n",
      "1336/1336 [==============================] - 1s 517us/step - loss: 0.5956 - accuracy: 0.6679 - val_loss: 0.6252 - val_accuracy: 0.6664\n",
      "Epoch 18/100\n",
      "1336/1336 [==============================] - 1s 513us/step - loss: 0.6089 - accuracy: 0.6678 - val_loss: 0.6720 - val_accuracy: 0.6664\n",
      "Epoch 19/100\n",
      "1336/1336 [==============================] - 1s 512us/step - loss: 0.5988 - accuracy: 0.6678 - val_loss: 0.6204 - val_accuracy: 0.6664\n",
      "Epoch 20/100\n",
      "1336/1336 [==============================] - 1s 515us/step - loss: 0.5931 - accuracy: 0.6679 - val_loss: 0.6245 - val_accuracy: 0.6664\n",
      "Epoch 21/100\n",
      "1336/1336 [==============================] - 1s 513us/step - loss: 0.5940 - accuracy: 0.6679 - val_loss: 0.6212 - val_accuracy: 0.6664\n",
      "Epoch 22/100\n",
      "1336/1336 [==============================] - 1s 517us/step - loss: 0.5930 - accuracy: 0.6678 - val_loss: 0.6239 - val_accuracy: 0.6664\n",
      "Epoch 23/100\n",
      "1336/1336 [==============================] - 1s 513us/step - loss: 0.5921 - accuracy: 0.6679 - val_loss: 0.6282 - val_accuracy: 0.6664\n",
      "Epoch 24/100\n",
      "1336/1336 [==============================] - 1s 515us/step - loss: 0.5869 - accuracy: 0.6836 - val_loss: 0.6577 - val_accuracy: 0.6752\n",
      "Epoch 25/100\n",
      "1336/1336 [==============================] - 1s 516us/step - loss: 0.5820 - accuracy: 0.6989 - val_loss: 0.6143 - val_accuracy: 0.6752\n",
      "Epoch 26/100\n",
      "1336/1336 [==============================] - 1s 517us/step - loss: 0.5822 - accuracy: 0.6975 - val_loss: 0.6113 - val_accuracy: 0.6792\n",
      "Epoch 27/100\n",
      "1336/1336 [==============================] - 1s 522us/step - loss: 0.5802 - accuracy: 0.6966 - val_loss: 0.6223 - val_accuracy: 0.6691\n",
      "Epoch 28/100\n",
      "1336/1336 [==============================] - 1s 514us/step - loss: 0.5797 - accuracy: 0.6978 - val_loss: 0.6385 - val_accuracy: 0.6658\n",
      "Epoch 29/100\n",
      "1336/1336 [==============================] - 1s 513us/step - loss: 0.5789 - accuracy: 0.7039 - val_loss: 0.6337 - val_accuracy: 0.6806\n",
      "Epoch 30/100\n",
      "1336/1336 [==============================] - 1s 518us/step - loss: 0.5792 - accuracy: 0.7000 - val_loss: 0.6188 - val_accuracy: 0.6718\n",
      "Epoch 31/100\n",
      "1336/1336 [==============================] - 1s 512us/step - loss: 0.5783 - accuracy: 0.7018 - val_loss: 0.6295 - val_accuracy: 0.6894\n",
      "Epoch 32/100\n",
      "1336/1336 [==============================] - 1s 521us/step - loss: 0.5773 - accuracy: 0.7017 - val_loss: 0.6330 - val_accuracy: 0.6840\n",
      "Epoch 33/100\n",
      "1336/1336 [==============================] - 1s 512us/step - loss: 0.5776 - accuracy: 0.7014 - val_loss: 0.6722 - val_accuracy: 0.6772\n",
      "Epoch 34/100\n",
      "1336/1336 [==============================] - 1s 516us/step - loss: 0.5830 - accuracy: 0.7005 - val_loss: 0.6253 - val_accuracy: 0.6772\n",
      "Epoch 35/100\n",
      "1336/1336 [==============================] - 1s 512us/step - loss: 0.5778 - accuracy: 0.7011 - val_loss: 0.6351 - val_accuracy: 0.6725\n",
      "Epoch 36/100\n",
      "1336/1336 [==============================] - 1s 521us/step - loss: 0.5749 - accuracy: 0.7037 - val_loss: 0.6413 - val_accuracy: 0.6786\n",
      "Epoch 37/100\n",
      "1336/1336 [==============================] - 1s 519us/step - loss: 0.5746 - accuracy: 0.7019 - val_loss: 0.6446 - val_accuracy: 0.6745\n",
      "Epoch 38/100\n",
      "1336/1336 [==============================] - 1s 518us/step - loss: 0.5761 - accuracy: 0.7029 - val_loss: 0.6205 - val_accuracy: 0.6772\n",
      "Epoch 39/100\n",
      "1336/1336 [==============================] - 1s 515us/step - loss: 0.5757 - accuracy: 0.7041 - val_loss: 0.6348 - val_accuracy: 0.6826\n",
      "Epoch 40/100\n",
      "1336/1336 [==============================] - 1s 519us/step - loss: 0.5753 - accuracy: 0.7071 - val_loss: 0.6532 - val_accuracy: 0.6786\n",
      "Epoch 41/100\n",
      "1336/1336 [==============================] - 1s 514us/step - loss: 0.5750 - accuracy: 0.7041 - val_loss: 0.6467 - val_accuracy: 0.6819\n",
      "Epoch 42/100\n",
      "1336/1336 [==============================] - 1s 514us/step - loss: 0.5733 - accuracy: 0.7041 - val_loss: 0.6521 - val_accuracy: 0.6772\n",
      "Epoch 43/100\n",
      "1336/1336 [==============================] - 1s 518us/step - loss: 0.5731 - accuracy: 0.7073 - val_loss: 0.6334 - val_accuracy: 0.6759\n",
      "Epoch 44/100\n",
      "1336/1336 [==============================] - 1s 516us/step - loss: 0.5740 - accuracy: 0.7073 - val_loss: 0.7528 - val_accuracy: 0.6792\n",
      "Epoch 45/100\n",
      "1336/1336 [==============================] - 1s 514us/step - loss: 0.5720 - accuracy: 0.7067 - val_loss: 0.7492 - val_accuracy: 0.6765\n",
      "Epoch 46/100\n",
      "1336/1336 [==============================] - 1s 519us/step - loss: 0.5717 - accuracy: 0.7072 - val_loss: 0.7562 - val_accuracy: 0.6833\n",
      "Epoch 47/100\n",
      "1336/1336 [==============================] - 1s 518us/step - loss: 0.5724 - accuracy: 0.7067 - val_loss: 0.7586 - val_accuracy: 0.6853\n",
      "Epoch 48/100\n",
      "1336/1336 [==============================] - 1s 517us/step - loss: 0.5760 - accuracy: 0.7056 - val_loss: 0.6287 - val_accuracy: 0.6765\n",
      "Epoch 49/100\n",
      "1336/1336 [==============================] - 1s 516us/step - loss: 0.5704 - accuracy: 0.7021 - val_loss: 0.6594 - val_accuracy: 0.6752\n",
      "Epoch 50/100\n",
      "1336/1336 [==============================] - 1s 515us/step - loss: 0.5704 - accuracy: 0.7059 - val_loss: 0.6555 - val_accuracy: 0.6894\n",
      "Epoch 51/100\n",
      "1336/1336 [==============================] - 1s 515us/step - loss: 0.5698 - accuracy: 0.7062 - val_loss: 0.6716 - val_accuracy: 0.6873\n",
      "Epoch 52/100\n",
      "1336/1336 [==============================] - 1s 518us/step - loss: 0.5708 - accuracy: 0.7065 - val_loss: 0.6483 - val_accuracy: 0.6786\n",
      "Epoch 53/100\n",
      "1336/1336 [==============================] - 1s 514us/step - loss: 0.5710 - accuracy: 0.7047 - val_loss: 0.6511 - val_accuracy: 0.6779\n",
      "Epoch 54/100\n",
      "1336/1336 [==============================] - 1s 534us/step - loss: 0.5735 - accuracy: 0.7061 - val_loss: 0.6319 - val_accuracy: 0.6826\n",
      "Epoch 55/100\n",
      "1336/1336 [==============================] - 1s 531us/step - loss: 0.5693 - accuracy: 0.7050 - val_loss: 0.6718 - val_accuracy: 0.6779\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1336/1336 [==============================] - 1s 522us/step - loss: 0.5688 - accuracy: 0.7063 - val_loss: 0.6546 - val_accuracy: 0.6792\n",
      "Epoch 57/100\n",
      "1336/1336 [==============================] - 1s 517us/step - loss: 0.5682 - accuracy: 0.7065 - val_loss: 0.6691 - val_accuracy: 0.6833\n",
      "Epoch 58/100\n",
      "1336/1336 [==============================] - 1s 513us/step - loss: 0.5673 - accuracy: 0.7068 - val_loss: 0.6617 - val_accuracy: 0.6873\n",
      "Epoch 59/100\n",
      "1336/1336 [==============================] - 1s 513us/step - loss: 0.5684 - accuracy: 0.7075 - val_loss: 0.6719 - val_accuracy: 0.6806\n",
      "Epoch 60/100\n",
      "1336/1336 [==============================] - 1s 509us/step - loss: 0.5684 - accuracy: 0.7069 - val_loss: 0.6874 - val_accuracy: 0.6900\n",
      "Epoch 61/100\n",
      "1336/1336 [==============================] - 1s 512us/step - loss: 0.5686 - accuracy: 0.7072 - val_loss: 0.6843 - val_accuracy: 0.6806\n",
      "Epoch 62/100\n",
      "1336/1336 [==============================] - 1s 511us/step - loss: 0.5675 - accuracy: 0.7090 - val_loss: 0.7097 - val_accuracy: 0.6772\n",
      "Epoch 63/100\n",
      "1336/1336 [==============================] - 1s 515us/step - loss: 0.5673 - accuracy: 0.7075 - val_loss: 0.7183 - val_accuracy: 0.6833\n",
      "Epoch 64/100\n",
      "1336/1336 [==============================] - 1s 515us/step - loss: 0.5659 - accuracy: 0.7053 - val_loss: 0.7760 - val_accuracy: 0.6819\n",
      "Epoch 65/100\n",
      "1336/1336 [==============================] - 1s 512us/step - loss: 0.5659 - accuracy: 0.7095 - val_loss: 0.7943 - val_accuracy: 0.6786\n",
      "Epoch 66/100\n",
      "1336/1336 [==============================] - 1s 517us/step - loss: 0.5652 - accuracy: 0.7112 - val_loss: 0.8565 - val_accuracy: 0.6840\n",
      "Epoch 67/100\n",
      "1336/1336 [==============================] - 1s 513us/step - loss: 0.5665 - accuracy: 0.7091 - val_loss: 0.7494 - val_accuracy: 0.6840\n",
      "Epoch 68/100\n",
      "1336/1336 [==============================] - 1s 508us/step - loss: 0.5639 - accuracy: 0.7092 - val_loss: 0.8156 - val_accuracy: 0.6792\n",
      "Epoch 69/100\n",
      "1336/1336 [==============================] - 1s 516us/step - loss: 0.5622 - accuracy: 0.7083 - val_loss: 0.8049 - val_accuracy: 0.6813\n",
      "Epoch 70/100\n",
      "1336/1336 [==============================] - 1s 510us/step - loss: 0.5652 - accuracy: 0.7065 - val_loss: 0.8647 - val_accuracy: 0.6934\n",
      "Epoch 71/100\n",
      "1336/1336 [==============================] - 1s 509us/step - loss: 0.5626 - accuracy: 0.7092 - val_loss: 0.8264 - val_accuracy: 0.6678\n",
      "Epoch 72/100\n",
      "1336/1336 [==============================] - 1s 512us/step - loss: 0.5633 - accuracy: 0.7097 - val_loss: 0.8050 - val_accuracy: 0.6745\n",
      "Epoch 73/100\n",
      "1336/1336 [==============================] - 1s 509us/step - loss: 0.5628 - accuracy: 0.7092 - val_loss: 0.9119 - val_accuracy: 0.6745\n",
      "Epoch 74/100\n",
      "1336/1336 [==============================] - 1s 515us/step - loss: 0.5719 - accuracy: 0.7086 - val_loss: 0.7824 - val_accuracy: 0.6779\n",
      "Epoch 75/100\n",
      "1336/1336 [==============================] - 1s 517us/step - loss: 0.5627 - accuracy: 0.7120 - val_loss: 0.8357 - val_accuracy: 0.6705\n",
      "Epoch 76/100\n",
      "1336/1336 [==============================] - 1s 516us/step - loss: 0.5617 - accuracy: 0.7114 - val_loss: 0.8263 - val_accuracy: 0.6718\n",
      "Epoch 77/100\n",
      "1336/1336 [==============================] - 1s 517us/step - loss: 0.5612 - accuracy: 0.7138 - val_loss: 0.8564 - val_accuracy: 0.6752\n",
      "Epoch 78/100\n",
      "1336/1336 [==============================] - 1s 516us/step - loss: 0.5589 - accuracy: 0.7105 - val_loss: 0.9935 - val_accuracy: 0.6712\n",
      "Epoch 79/100\n",
      "1336/1336 [==============================] - 1s 511us/step - loss: 0.5603 - accuracy: 0.7086 - val_loss: 0.8330 - val_accuracy: 0.6819\n",
      "Epoch 80/100\n",
      "1336/1336 [==============================] - 1s 509us/step - loss: 0.5621 - accuracy: 0.7121 - val_loss: 0.7327 - val_accuracy: 0.6853\n",
      "Epoch 81/100\n",
      "1336/1336 [==============================] - 1s 511us/step - loss: 0.5588 - accuracy: 0.7125 - val_loss: 0.7274 - val_accuracy: 0.6712\n",
      "Epoch 82/100\n",
      "1336/1336 [==============================] - 1s 514us/step - loss: 0.5602 - accuracy: 0.7115 - val_loss: 0.7764 - val_accuracy: 0.6739\n",
      "Epoch 83/100\n",
      "1336/1336 [==============================] - 1s 510us/step - loss: 0.5573 - accuracy: 0.7126 - val_loss: 0.8553 - val_accuracy: 0.6664\n",
      "Epoch 84/100\n",
      "1336/1336 [==============================] - 1s 513us/step - loss: 0.5593 - accuracy: 0.7134 - val_loss: 0.7604 - val_accuracy: 0.6786\n",
      "Epoch 85/100\n",
      "1336/1336 [==============================] - 1s 511us/step - loss: 0.5578 - accuracy: 0.7149 - val_loss: 0.8066 - val_accuracy: 0.6806\n",
      "Epoch 86/100\n",
      "1336/1336 [==============================] - 1s 508us/step - loss: 0.5570 - accuracy: 0.7139 - val_loss: 0.7574 - val_accuracy: 0.6786\n",
      "Epoch 87/100\n",
      "1336/1336 [==============================] - 1s 510us/step - loss: 0.5574 - accuracy: 0.7142 - val_loss: 0.7754 - val_accuracy: 0.6806\n",
      "Epoch 88/100\n",
      "1336/1336 [==============================] - 1s 511us/step - loss: 0.5623 - accuracy: 0.7133 - val_loss: 0.7902 - val_accuracy: 0.6772\n",
      "Epoch 89/100\n",
      "1336/1336 [==============================] - 1s 505us/step - loss: 0.5582 - accuracy: 0.7135 - val_loss: 0.7751 - val_accuracy: 0.6779\n",
      "Epoch 90/100\n",
      "1336/1336 [==============================] - 1s 515us/step - loss: 0.5566 - accuracy: 0.7122 - val_loss: 0.8767 - val_accuracy: 0.6819\n",
      "Epoch 91/100\n",
      "1336/1336 [==============================] - 1s 508us/step - loss: 0.5550 - accuracy: 0.7142 - val_loss: 0.8432 - val_accuracy: 0.6813\n",
      "Epoch 92/100\n",
      "1336/1336 [==============================] - 1s 509us/step - loss: 0.5548 - accuracy: 0.7171 - val_loss: 0.8531 - val_accuracy: 0.6698\n",
      "Epoch 93/100\n",
      "1336/1336 [==============================] - 1s 510us/step - loss: 0.5570 - accuracy: 0.7145 - val_loss: 0.7005 - val_accuracy: 0.6725\n",
      "Epoch 94/100\n",
      "1336/1336 [==============================] - 1s 512us/step - loss: 0.5550 - accuracy: 0.7115 - val_loss: 0.7782 - val_accuracy: 0.6759\n",
      "Epoch 95/100\n",
      "1336/1336 [==============================] - 1s 512us/step - loss: 0.5545 - accuracy: 0.7164 - val_loss: 0.7998 - val_accuracy: 0.6597\n",
      "Epoch 96/100\n",
      "1336/1336 [==============================] - 1s 510us/step - loss: 0.5548 - accuracy: 0.7148 - val_loss: 0.8034 - val_accuracy: 0.6772\n",
      "Epoch 97/100\n",
      "1336/1336 [==============================] - 1s 454us/step - loss: 0.5543 - accuracy: 0.7148 - val_loss: 0.8388 - val_accuracy: 0.6685\n",
      "Epoch 98/100\n",
      "1336/1336 [==============================] - 1s 525us/step - loss: 0.5546 - accuracy: 0.7136 - val_loss: 0.7973 - val_accuracy: 0.6718\n",
      "Epoch 99/100\n",
      "1336/1336 [==============================] - 1s 544us/step - loss: 0.5517 - accuracy: 0.7167 - val_loss: 0.8162 - val_accuracy: 0.6792\n",
      "Epoch 100/100\n",
      "1336/1336 [==============================] - 1s 509us/step - loss: 0.5503 - accuracy: 0.7151 - val_loss: 0.9833 - val_accuracy: 0.6732\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x28eabebc0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model1.fit(X_train, EC1_train, epochs=100, batch_size=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36d5a01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1336/1336 [==============================] - 1s 553us/step - loss: 0.5575 - accuracy: 0.7942 - val_loss: 0.5439 - val_accuracy: 0.7857\n",
      "Epoch 2/100\n",
      "1336/1336 [==============================] - 1s 513us/step - loss: 0.5124 - accuracy: 0.7992 - val_loss: 0.5311 - val_accuracy: 0.7857\n",
      "Epoch 3/100\n",
      "1336/1336 [==============================] - 1s 510us/step - loss: 0.5058 - accuracy: 0.7995 - val_loss: 0.5283 - val_accuracy: 0.7857\n",
      "Epoch 4/100\n",
      "1336/1336 [==============================] - 1s 520us/step - loss: 0.5022 - accuracy: 0.7996 - val_loss: 0.5255 - val_accuracy: 0.7871\n",
      "Epoch 5/100\n",
      "1336/1336 [==============================] - 1s 549us/step - loss: 0.5009 - accuracy: 0.8004 - val_loss: 0.5265 - val_accuracy: 0.7871\n",
      "Epoch 6/100\n",
      "1336/1336 [==============================] - 1s 562us/step - loss: 0.4985 - accuracy: 0.8004 - val_loss: 0.5255 - val_accuracy: 0.7871\n",
      "Epoch 7/100\n",
      "1336/1336 [==============================] - 1s 503us/step - loss: 0.4989 - accuracy: 0.8003 - val_loss: 0.5230 - val_accuracy: 0.7871\n",
      "Epoch 8/100\n",
      "1336/1336 [==============================] - 1s 501us/step - loss: 0.4968 - accuracy: 0.8003 - val_loss: 0.5371 - val_accuracy: 0.7871\n",
      "Epoch 9/100\n",
      "1336/1336 [==============================] - 1s 504us/step - loss: 0.4965 - accuracy: 0.8002 - val_loss: 0.5287 - val_accuracy: 0.7871\n",
      "Epoch 10/100\n",
      "1336/1336 [==============================] - 1s 506us/step - loss: 0.4953 - accuracy: 0.8003 - val_loss: 0.5304 - val_accuracy: 0.7871\n",
      "Epoch 11/100\n",
      "1336/1336 [==============================] - 1s 516us/step - loss: 0.4944 - accuracy: 0.8004 - val_loss: 0.5305 - val_accuracy: 0.7864\n",
      "Epoch 12/100\n",
      "1336/1336 [==============================] - 1s 516us/step - loss: 0.4949 - accuracy: 0.8001 - val_loss: 0.5368 - val_accuracy: 0.7871\n",
      "Epoch 13/100\n",
      "1336/1336 [==============================] - 1s 513us/step - loss: 0.4961 - accuracy: 0.8003 - val_loss: 0.5277 - val_accuracy: 0.7871\n",
      "Epoch 14/100\n",
      "1336/1336 [==============================] - 1s 511us/step - loss: 0.4931 - accuracy: 0.8003 - val_loss: 0.5319 - val_accuracy: 0.7871\n",
      "Epoch 15/100\n",
      "1336/1336 [==============================] - 1s 512us/step - loss: 0.4916 - accuracy: 0.8004 - val_loss: 0.5341 - val_accuracy: 0.7871\n",
      "Epoch 16/100\n",
      "1336/1336 [==============================] - 1s 512us/step - loss: 0.4918 - accuracy: 0.8003 - val_loss: 0.5308 - val_accuracy: 0.7871\n",
      "Epoch 17/100\n",
      "1336/1336 [==============================] - 1s 518us/step - loss: 0.4929 - accuracy: 0.8004 - val_loss: 0.5492 - val_accuracy: 0.7871\n",
      "Epoch 18/100\n",
      "1336/1336 [==============================] - 1s 515us/step - loss: 0.4931 - accuracy: 0.8006 - val_loss: 0.5245 - val_accuracy: 0.7871\n",
      "Epoch 19/100\n",
      "1336/1336 [==============================] - 1s 511us/step - loss: 0.4908 - accuracy: 0.8004 - val_loss: 0.5426 - val_accuracy: 0.7871\n",
      "Epoch 20/100\n",
      "1336/1336 [==============================] - 1s 512us/step - loss: 0.4908 - accuracy: 0.8005 - val_loss: 0.5318 - val_accuracy: 0.7864\n",
      "Epoch 21/100\n",
      "1336/1336 [==============================] - 1s 515us/step - loss: 0.4902 - accuracy: 0.8006 - val_loss: 0.5289 - val_accuracy: 0.7864\n",
      "Epoch 22/100\n",
      "1336/1336 [==============================] - 1s 515us/step - loss: 0.4897 - accuracy: 0.8006 - val_loss: 0.5345 - val_accuracy: 0.7844\n",
      "Epoch 23/100\n",
      "1336/1336 [==============================] - 1s 511us/step - loss: 0.4906 - accuracy: 0.8008 - val_loss: 0.5388 - val_accuracy: 0.7844\n",
      "Epoch 24/100\n",
      "1336/1336 [==============================] - 1s 514us/step - loss: 0.4901 - accuracy: 0.8010 - val_loss: 0.5622 - val_accuracy: 0.7850\n",
      "Epoch 25/100\n",
      "1336/1336 [==============================] - 1s 515us/step - loss: 0.4899 - accuracy: 0.8010 - val_loss: 0.5409 - val_accuracy: 0.7850\n",
      "Epoch 26/100\n",
      "1336/1336 [==============================] - 1s 529us/step - loss: 0.4905 - accuracy: 0.8008 - val_loss: 0.5484 - val_accuracy: 0.7844\n",
      "Epoch 27/100\n",
      "1336/1336 [==============================] - 1s 521us/step - loss: 0.4889 - accuracy: 0.8008 - val_loss: 0.5485 - val_accuracy: 0.7850\n",
      "Epoch 28/100\n",
      "1336/1336 [==============================] - 1s 521us/step - loss: 0.4885 - accuracy: 0.8010 - val_loss: 0.5475 - val_accuracy: 0.7850\n",
      "Epoch 29/100\n",
      "1336/1336 [==============================] - 1s 515us/step - loss: 0.4883 - accuracy: 0.8008 - val_loss: 0.5433 - val_accuracy: 0.7850\n",
      "Epoch 30/100\n",
      "1336/1336 [==============================] - 1s 530us/step - loss: 0.4888 - accuracy: 0.8007 - val_loss: 0.5472 - val_accuracy: 0.7857\n",
      "Epoch 31/100\n",
      "1336/1336 [==============================] - 1s 530us/step - loss: 0.4896 - accuracy: 0.8007 - val_loss: 0.5334 - val_accuracy: 0.7844\n",
      "Epoch 32/100\n",
      "1336/1336 [==============================] - 1s 527us/step - loss: 0.4874 - accuracy: 0.8012 - val_loss: 0.5955 - val_accuracy: 0.7844\n",
      "Epoch 33/100\n",
      "1336/1336 [==============================] - 1s 523us/step - loss: 0.4888 - accuracy: 0.8011 - val_loss: 0.5369 - val_accuracy: 0.7837\n",
      "Epoch 34/100\n",
      "1336/1336 [==============================] - 1s 515us/step - loss: 0.4887 - accuracy: 0.8010 - val_loss: 0.5546 - val_accuracy: 0.7844\n",
      "Epoch 35/100\n",
      "1336/1336 [==============================] - 1s 518us/step - loss: 0.4887 - accuracy: 0.8007 - val_loss: 0.5497 - val_accuracy: 0.7850\n",
      "Epoch 36/100\n",
      "1336/1336 [==============================] - 1s 519us/step - loss: 0.4902 - accuracy: 0.8009 - val_loss: 0.5396 - val_accuracy: 0.7850\n",
      "Epoch 37/100\n",
      "1336/1336 [==============================] - 1s 523us/step - loss: 0.4892 - accuracy: 0.8010 - val_loss: 0.5538 - val_accuracy: 0.7844\n",
      "Epoch 38/100\n",
      "1336/1336 [==============================] - 1s 532us/step - loss: 0.4880 - accuracy: 0.8016 - val_loss: 0.5567 - val_accuracy: 0.7850\n",
      "Epoch 39/100\n",
      "1336/1336 [==============================] - 1s 522us/step - loss: 0.4888 - accuracy: 0.8013 - val_loss: 0.5521 - val_accuracy: 0.7850\n",
      "Epoch 40/100\n",
      "1336/1336 [==============================] - 1s 524us/step - loss: 0.4875 - accuracy: 0.8013 - val_loss: 0.5558 - val_accuracy: 0.7844\n",
      "Epoch 41/100\n",
      "1336/1336 [==============================] - 1s 526us/step - loss: 0.4894 - accuracy: 0.8013 - val_loss: 0.5445 - val_accuracy: 0.7844\n",
      "Epoch 42/100\n",
      "1336/1336 [==============================] - 1s 523us/step - loss: 0.4881 - accuracy: 0.8012 - val_loss: 0.5489 - val_accuracy: 0.7850\n",
      "Epoch 43/100\n",
      "1336/1336 [==============================] - 1s 527us/step - loss: 0.4872 - accuracy: 0.8012 - val_loss: 0.5588 - val_accuracy: 0.7844\n",
      "Epoch 44/100\n",
      "1336/1336 [==============================] - 1s 519us/step - loss: 0.4881 - accuracy: 0.8013 - val_loss: 0.5634 - val_accuracy: 0.7830\n",
      "Epoch 45/100\n",
      "1336/1336 [==============================] - 1s 524us/step - loss: 0.4885 - accuracy: 0.8015 - val_loss: 0.5375 - val_accuracy: 0.7850\n",
      "Epoch 46/100\n",
      "1336/1336 [==============================] - 1s 524us/step - loss: 0.4880 - accuracy: 0.8016 - val_loss: 0.5555 - val_accuracy: 0.7844\n",
      "Epoch 47/100\n",
      "1336/1336 [==============================] - 1s 522us/step - loss: 0.4857 - accuracy: 0.8015 - val_loss: 0.5515 - val_accuracy: 0.7844\n",
      "Epoch 48/100\n",
      "1336/1336 [==============================] - 1s 524us/step - loss: 0.4872 - accuracy: 0.8019 - val_loss: 0.5774 - val_accuracy: 0.7823\n",
      "Epoch 49/100\n",
      "1336/1336 [==============================] - 1s 520us/step - loss: 0.4888 - accuracy: 0.8014 - val_loss: 0.5517 - val_accuracy: 0.7850\n",
      "Epoch 50/100\n",
      "1336/1336 [==============================] - 1s 525us/step - loss: 0.4917 - accuracy: 0.8012 - val_loss: 0.5573 - val_accuracy: 0.7837\n",
      "Epoch 51/100\n",
      "1336/1336 [==============================] - 1s 526us/step - loss: 0.4879 - accuracy: 0.8019 - val_loss: 0.5684 - val_accuracy: 0.7857\n",
      "Epoch 52/100\n",
      "1336/1336 [==============================] - 1s 521us/step - loss: 0.4891 - accuracy: 0.8016 - val_loss: 0.5527 - val_accuracy: 0.7857\n",
      "Epoch 53/100\n",
      "1336/1336 [==============================] - 1s 512us/step - loss: 0.4876 - accuracy: 0.8016 - val_loss: 0.5674 - val_accuracy: 0.7844\n",
      "Epoch 54/100\n",
      "1336/1336 [==============================] - 1s 515us/step - loss: 0.4858 - accuracy: 0.8019 - val_loss: 0.5651 - val_accuracy: 0.7857\n",
      "Epoch 55/100\n",
      "1336/1336 [==============================] - 1s 522us/step - loss: 0.4872 - accuracy: 0.8015 - val_loss: 0.5580 - val_accuracy: 0.7871\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1336/1336 [==============================] - 1s 517us/step - loss: 0.4873 - accuracy: 0.8015 - val_loss: 0.5818 - val_accuracy: 0.7850\n",
      "Epoch 57/100\n",
      "1336/1336 [==============================] - 1s 519us/step - loss: 0.4872 - accuracy: 0.8018 - val_loss: 0.5417 - val_accuracy: 0.7864\n",
      "Epoch 58/100\n",
      "1336/1336 [==============================] - 1s 518us/step - loss: 0.4877 - accuracy: 0.8020 - val_loss: 0.5640 - val_accuracy: 0.7850\n",
      "Epoch 59/100\n",
      "1336/1336 [==============================] - 1s 515us/step - loss: 0.4857 - accuracy: 0.8023 - val_loss: 0.5532 - val_accuracy: 0.7844\n",
      "Epoch 60/100\n",
      "1336/1336 [==============================] - 1s 519us/step - loss: 0.4843 - accuracy: 0.8019 - val_loss: 0.5581 - val_accuracy: 0.7850\n",
      "Epoch 61/100\n",
      "1336/1336 [==============================] - 1s 518us/step - loss: 0.4859 - accuracy: 0.8013 - val_loss: 0.5437 - val_accuracy: 0.7850\n",
      "Epoch 62/100\n",
      "1336/1336 [==============================] - 1s 515us/step - loss: 0.4858 - accuracy: 0.8019 - val_loss: 0.5524 - val_accuracy: 0.7844\n",
      "Epoch 63/100\n",
      "1336/1336 [==============================] - 1s 519us/step - loss: 0.4835 - accuracy: 0.8016 - val_loss: 0.5511 - val_accuracy: 0.7864\n",
      "Epoch 64/100\n",
      "1336/1336 [==============================] - 1s 517us/step - loss: 0.4846 - accuracy: 0.8019 - val_loss: 0.5993 - val_accuracy: 0.7850\n",
      "Epoch 65/100\n",
      "1336/1336 [==============================] - 1s 520us/step - loss: 0.4836 - accuracy: 0.8020 - val_loss: 0.5622 - val_accuracy: 0.7864\n",
      "Epoch 66/100\n",
      "1336/1336 [==============================] - 1s 521us/step - loss: 0.4831 - accuracy: 0.8024 - val_loss: 0.5971 - val_accuracy: 0.7844\n",
      "Epoch 67/100\n",
      "1336/1336 [==============================] - 1s 525us/step - loss: 0.4821 - accuracy: 0.8025 - val_loss: 0.6090 - val_accuracy: 0.7844\n",
      "Epoch 68/100\n",
      "1336/1336 [==============================] - 1s 531us/step - loss: 0.4844 - accuracy: 0.8024 - val_loss: 0.5875 - val_accuracy: 0.7850\n",
      "Epoch 69/100\n",
      "1336/1336 [==============================] - 1s 527us/step - loss: 0.4844 - accuracy: 0.8016 - val_loss: 0.6463 - val_accuracy: 0.7830\n",
      "Epoch 70/100\n",
      "1336/1336 [==============================] - 1s 520us/step - loss: 0.4825 - accuracy: 0.8022 - val_loss: 0.6463 - val_accuracy: 0.7837\n",
      "Epoch 71/100\n",
      "1336/1336 [==============================] - 1s 536us/step - loss: 0.4821 - accuracy: 0.8023 - val_loss: 0.5865 - val_accuracy: 0.7857\n",
      "Epoch 72/100\n",
      "1336/1336 [==============================] - 1s 518us/step - loss: 0.4817 - accuracy: 0.8022 - val_loss: 0.6702 - val_accuracy: 0.7830\n",
      "Epoch 73/100\n",
      "1336/1336 [==============================] - 1s 519us/step - loss: 0.4851 - accuracy: 0.8019 - val_loss: 0.5655 - val_accuracy: 0.7844\n",
      "Epoch 74/100\n",
      "1336/1336 [==============================] - 1s 517us/step - loss: 0.4818 - accuracy: 0.8024 - val_loss: 0.5716 - val_accuracy: 0.7864\n",
      "Epoch 75/100\n",
      "1336/1336 [==============================] - 1s 522us/step - loss: 0.4832 - accuracy: 0.8025 - val_loss: 0.6299 - val_accuracy: 0.7844\n",
      "Epoch 76/100\n",
      "1336/1336 [==============================] - 1s 518us/step - loss: 0.4812 - accuracy: 0.8031 - val_loss: 0.5737 - val_accuracy: 0.7844\n",
      "Epoch 77/100\n",
      "1336/1336 [==============================] - 1s 517us/step - loss: 0.4844 - accuracy: 0.8022 - val_loss: 0.5734 - val_accuracy: 0.7857\n",
      "Epoch 78/100\n",
      "1336/1336 [==============================] - 1s 516us/step - loss: 0.4838 - accuracy: 0.8016 - val_loss: 0.5616 - val_accuracy: 0.7850\n",
      "Epoch 79/100\n",
      "1336/1336 [==============================] - 1s 518us/step - loss: 0.4820 - accuracy: 0.8020 - val_loss: 0.6109 - val_accuracy: 0.7857\n",
      "Epoch 80/100\n",
      "1336/1336 [==============================] - 1s 520us/step - loss: 0.4816 - accuracy: 0.8024 - val_loss: 0.6043 - val_accuracy: 0.7857\n",
      "Epoch 81/100\n",
      "1336/1336 [==============================] - 1s 524us/step - loss: 0.4873 - accuracy: 0.8025 - val_loss: 0.5892 - val_accuracy: 0.7837\n",
      "Epoch 82/100\n",
      "1336/1336 [==============================] - 1s 519us/step - loss: 0.4842 - accuracy: 0.8025 - val_loss: 0.5885 - val_accuracy: 0.7857\n",
      "Epoch 83/100\n",
      "1336/1336 [==============================] - 1s 518us/step - loss: 0.4818 - accuracy: 0.8030 - val_loss: 0.6293 - val_accuracy: 0.7850\n",
      "Epoch 84/100\n",
      "1336/1336 [==============================] - 1s 523us/step - loss: 0.4821 - accuracy: 0.8023 - val_loss: 0.5846 - val_accuracy: 0.7864\n",
      "Epoch 85/100\n",
      "1336/1336 [==============================] - 1s 516us/step - loss: 0.4830 - accuracy: 0.8028 - val_loss: 0.5829 - val_accuracy: 0.7844\n",
      "Epoch 86/100\n",
      "1336/1336 [==============================] - 1s 518us/step - loss: 0.4790 - accuracy: 0.8036 - val_loss: 0.6096 - val_accuracy: 0.7850\n",
      "Epoch 87/100\n",
      "1336/1336 [==============================] - 1s 525us/step - loss: 0.4784 - accuracy: 0.8034 - val_loss: 0.5809 - val_accuracy: 0.7837\n",
      "Epoch 88/100\n",
      "1336/1336 [==============================] - 1s 519us/step - loss: 0.4816 - accuracy: 0.8026 - val_loss: 0.6020 - val_accuracy: 0.7837\n",
      "Epoch 89/100\n",
      "1336/1336 [==============================] - 1s 520us/step - loss: 0.4792 - accuracy: 0.8033 - val_loss: 0.6170 - val_accuracy: 0.7844\n",
      "Epoch 90/100\n",
      "1336/1336 [==============================] - 1s 524us/step - loss: 0.4791 - accuracy: 0.8026 - val_loss: 0.6421 - val_accuracy: 0.7823\n",
      "Epoch 91/100\n",
      "1336/1336 [==============================] - 1s 512us/step - loss: 0.4835 - accuracy: 0.8024 - val_loss: 0.6716 - val_accuracy: 0.7844\n",
      "Epoch 92/100\n",
      "1336/1336 [==============================] - 1s 516us/step - loss: 0.4803 - accuracy: 0.8029 - val_loss: 0.6034 - val_accuracy: 0.7857\n",
      "Epoch 93/100\n",
      "1336/1336 [==============================] - 1s 523us/step - loss: 0.4815 - accuracy: 0.8025 - val_loss: 0.6141 - val_accuracy: 0.7837\n",
      "Epoch 94/100\n",
      "1336/1336 [==============================] - 1s 528us/step - loss: 0.4779 - accuracy: 0.8039 - val_loss: 0.6069 - val_accuracy: 0.7830\n",
      "Epoch 95/100\n",
      "1336/1336 [==============================] - 1s 518us/step - loss: 0.4787 - accuracy: 0.8033 - val_loss: 0.6248 - val_accuracy: 0.7850\n",
      "Epoch 96/100\n",
      "1336/1336 [==============================] - 1s 521us/step - loss: 0.4792 - accuracy: 0.8028 - val_loss: 0.5869 - val_accuracy: 0.7844\n",
      "Epoch 97/100\n",
      "1336/1336 [==============================] - 1s 523us/step - loss: 0.4776 - accuracy: 0.8033 - val_loss: 0.6067 - val_accuracy: 0.7837\n",
      "Epoch 98/100\n",
      "1336/1336 [==============================] - 1s 521us/step - loss: 0.4789 - accuracy: 0.8027 - val_loss: 0.6024 - val_accuracy: 0.7837\n",
      "Epoch 99/100\n",
      "1336/1336 [==============================] - 1s 519us/step - loss: 0.4816 - accuracy: 0.8034 - val_loss: 0.6398 - val_accuracy: 0.7844\n",
      "Epoch 100/100\n",
      "1336/1336 [==============================] - 1s 519us/step - loss: 0.4784 - accuracy: 0.8041 - val_loss: 0.6118 - val_accuracy: 0.7844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x29c2b0e20>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model2.fit(X_train, EC2_train, epochs=100, batch_size=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "122cbe6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310/310 [==============================] - 0s 279us/step\n",
      "310/310 [==============================] - 0s 252us/step\n",
      "EC1 Predictions: [[0.81827444]\n",
      " [0.73020476]\n",
      " [0.823533  ]\n",
      " ...\n",
      " [0.8524922 ]\n",
      " [0.8983666 ]\n",
      " [0.87623703]]\n",
      "EC2 Predictions: [[0.81827444]\n",
      " [0.73020476]\n",
      " [0.823533  ]\n",
      " ...\n",
      " [0.8524922 ]\n",
      " [0.8983666 ]\n",
      " [0.87623703]]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test dataset for EC1\n",
    "EC1_pred = model1.predict(X_test)\n",
    "\n",
    "# Make predictions on the test dataset for EC2\n",
    "EC2_pred = model2.predict(X_test)\n",
    "\n",
    "# Print the predictions\n",
    "print(\"EC1 Predictions:\", EC1_pred)\n",
    "print(\"EC2 Predictions:\", EC2_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c840b3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_samp['EC1'] = EC1_pred\n",
    "df_samp['EC2'] = EC2_pred\n",
    "\n",
    "df_samp.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3b3e474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>EC1</th>\n",
       "      <th>EC2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14838</td>\n",
       "      <td>0.818274</td>\n",
       "      <td>0.818274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14839</td>\n",
       "      <td>0.730205</td>\n",
       "      <td>0.730205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14840</td>\n",
       "      <td>0.823533</td>\n",
       "      <td>0.823533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14841</td>\n",
       "      <td>0.860301</td>\n",
       "      <td>0.860301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14842</td>\n",
       "      <td>0.809497</td>\n",
       "      <td>0.809497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9888</th>\n",
       "      <td>24726</td>\n",
       "      <td>0.795767</td>\n",
       "      <td>0.795767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9889</th>\n",
       "      <td>24727</td>\n",
       "      <td>0.948245</td>\n",
       "      <td>0.948245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9890</th>\n",
       "      <td>24728</td>\n",
       "      <td>0.852492</td>\n",
       "      <td>0.852492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9891</th>\n",
       "      <td>24729</td>\n",
       "      <td>0.898367</td>\n",
       "      <td>0.898367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9892</th>\n",
       "      <td>24730</td>\n",
       "      <td>0.876237</td>\n",
       "      <td>0.876237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9893 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id       EC1       EC2\n",
       "0     14838  0.818274  0.818274\n",
       "1     14839  0.730205  0.730205\n",
       "2     14840  0.823533  0.823533\n",
       "3     14841  0.860301  0.860301\n",
       "4     14842  0.809497  0.809497\n",
       "...     ...       ...       ...\n",
       "9888  24726  0.795767  0.795767\n",
       "9889  24727  0.948245  0.948245\n",
       "9890  24728  0.852492  0.852492\n",
       "9891  24729  0.898367  0.898367\n",
       "9892  24730  0.876237  0.876237\n",
       "\n",
       "[9893 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53bb7dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "418/418 [==============================] - 0s 694us/step - loss: 0.8717 - accuracy: 0.6541 - val_loss: 0.6553 - val_accuracy: 0.6664\n",
      "Epoch 2/100\n",
      "418/418 [==============================] - 0s 590us/step - loss: 0.6560 - accuracy: 0.6664 - val_loss: 0.6410 - val_accuracy: 0.6664\n",
      "Epoch 3/100\n",
      "418/418 [==============================] - 0s 591us/step - loss: 0.6394 - accuracy: 0.6674 - val_loss: 0.6374 - val_accuracy: 0.6664\n",
      "Epoch 4/100\n",
      "418/418 [==============================] - 0s 601us/step - loss: 0.6371 - accuracy: 0.6675 - val_loss: 0.6368 - val_accuracy: 0.6664\n",
      "Epoch 5/100\n",
      "418/418 [==============================] - 0s 580us/step - loss: 0.6425 - accuracy: 0.6674 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 6/100\n",
      "418/418 [==============================] - 0s 567us/step - loss: 0.6396 - accuracy: 0.6675 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 7/100\n",
      "418/418 [==============================] - 0s 580us/step - loss: 0.6359 - accuracy: 0.6678 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 8/100\n",
      "418/418 [==============================] - 0s 580us/step - loss: 0.6356 - accuracy: 0.6680 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 9/100\n",
      "418/418 [==============================] - 0s 579us/step - loss: 0.6355 - accuracy: 0.6680 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 10/100\n",
      "418/418 [==============================] - 0s 580us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 11/100\n",
      "418/418 [==============================] - 0s 583us/step - loss: 0.6366 - accuracy: 0.6680 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 12/100\n",
      "418/418 [==============================] - 0s 572us/step - loss: 0.6364 - accuracy: 0.6678 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 13/100\n",
      "418/418 [==============================] - 0s 572us/step - loss: 0.6361 - accuracy: 0.6678 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 14/100\n",
      "418/418 [==============================] - 0s 581us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 15/100\n",
      "418/418 [==============================] - 0s 579us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 16/100\n",
      "418/418 [==============================] - 0s 576us/step - loss: 0.6362 - accuracy: 0.6678 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 17/100\n",
      "418/418 [==============================] - 0s 586us/step - loss: 0.6358 - accuracy: 0.6678 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 18/100\n",
      "418/418 [==============================] - 0s 593us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 19/100\n",
      "418/418 [==============================] - 0s 623us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 20/100\n",
      "418/418 [==============================] - 0s 576us/step - loss: 0.6362 - accuracy: 0.6678 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 21/100\n",
      "418/418 [==============================] - 0s 586us/step - loss: 0.6359 - accuracy: 0.6678 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 22/100\n",
      "418/418 [==============================] - 0s 587us/step - loss: 0.6358 - accuracy: 0.6678 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 23/100\n",
      "418/418 [==============================] - 0s 583us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 24/100\n",
      "418/418 [==============================] - 0s 582us/step - loss: 0.6360 - accuracy: 0.6678 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 25/100\n",
      "418/418 [==============================] - 0s 581us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 26/100\n",
      "418/418 [==============================] - 0s 582us/step - loss: 0.6360 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 27/100\n",
      "418/418 [==============================] - 0s 589us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 28/100\n",
      "418/418 [==============================] - 0s 612us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 29/100\n",
      "418/418 [==============================] - 0s 602us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 30/100\n",
      "418/418 [==============================] - 0s 605us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 31/100\n",
      "418/418 [==============================] - 0s 595us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 32/100\n",
      "418/418 [==============================] - 0s 585us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 33/100\n",
      "418/418 [==============================] - 0s 590us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 34/100\n",
      "418/418 [==============================] - 0s 596us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 35/100\n",
      "418/418 [==============================] - 0s 591us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 36/100\n",
      "418/418 [==============================] - 0s 609us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 37/100\n",
      "418/418 [==============================] - 0s 584us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 38/100\n",
      "418/418 [==============================] - 0s 589us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 39/100\n",
      "418/418 [==============================] - 0s 578us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 40/100\n",
      "418/418 [==============================] - 0s 579us/step - loss: 0.6358 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 41/100\n",
      "418/418 [==============================] - 0s 605us/step - loss: 0.6358 - accuracy: 0.6678 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 42/100\n",
      "418/418 [==============================] - 0s 601us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 43/100\n",
      "418/418 [==============================] - 0s 615us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 44/100\n",
      "418/418 [==============================] - 0s 606us/step - loss: 0.6360 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 45/100\n",
      "418/418 [==============================] - 0s 605us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 46/100\n",
      "418/418 [==============================] - 0s 593us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 47/100\n",
      "418/418 [==============================] - 0s 602us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 48/100\n",
      "418/418 [==============================] - 0s 610us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 49/100\n",
      "418/418 [==============================] - 0s 579us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 50/100\n",
      "418/418 [==============================] - 0s 573us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 51/100\n",
      "418/418 [==============================] - 0s 576us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 52/100\n",
      "418/418 [==============================] - 0s 587us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 53/100\n",
      "418/418 [==============================] - 0s 613us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 54/100\n",
      "418/418 [==============================] - 0s 596us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 55/100\n",
      "418/418 [==============================] - 0s 606us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 56/100\n",
      "418/418 [==============================] - 0s 605us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418/418 [==============================] - 0s 606us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 58/100\n",
      "418/418 [==============================] - 0s 584us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 59/100\n",
      "418/418 [==============================] - 0s 568us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 60/100\n",
      "418/418 [==============================] - 0s 570us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 61/100\n",
      "418/418 [==============================] - 0s 578us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 62/100\n",
      "418/418 [==============================] - 0s 578us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 63/100\n",
      "418/418 [==============================] - 0s 584us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 64/100\n",
      "418/418 [==============================] - 0s 596us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 65/100\n",
      "418/418 [==============================] - 0s 598us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 66/100\n",
      "418/418 [==============================] - 0s 585us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 67/100\n",
      "418/418 [==============================] - 0s 569us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 68/100\n",
      "418/418 [==============================] - 0s 576us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 69/100\n",
      "418/418 [==============================] - 0s 597us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 70/100\n",
      "418/418 [==============================] - 0s 591us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 71/100\n",
      "418/418 [==============================] - 0s 592us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 72/100\n",
      "418/418 [==============================] - 0s 582us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 73/100\n",
      "418/418 [==============================] - 0s 578us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 74/100\n",
      "418/418 [==============================] - 0s 574us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 75/100\n",
      "418/418 [==============================] - 0s 588us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 76/100\n",
      "418/418 [==============================] - 0s 587us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 77/100\n",
      "418/418 [==============================] - 0s 584us/step - loss: 0.6359 - accuracy: 0.6678 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 78/100\n",
      "418/418 [==============================] - 0s 578us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 79/100\n",
      "418/418 [==============================] - 0s 578us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 80/100\n",
      "418/418 [==============================] - 0s 587us/step - loss: 0.6370 - accuracy: 0.6680 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 81/100\n",
      "418/418 [==============================] - 0s 599us/step - loss: 0.6356 - accuracy: 0.6680 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 82/100\n",
      "418/418 [==============================] - 0s 594us/step - loss: 0.6368 - accuracy: 0.6678 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 83/100\n",
      "418/418 [==============================] - 0s 583us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 84/100\n",
      "418/418 [==============================] - 0s 578us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 85/100\n",
      "418/418 [==============================] - 0s 581us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 86/100\n",
      "418/418 [==============================] - 0s 595us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 87/100\n",
      "418/418 [==============================] - 0s 602us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 88/100\n",
      "418/418 [==============================] - 0s 588us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 89/100\n",
      "418/418 [==============================] - 0s 594us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 90/100\n",
      "418/418 [==============================] - 0s 597us/step - loss: 0.6364 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 91/100\n",
      "418/418 [==============================] - 0s 590us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 92/100\n",
      "418/418 [==============================] - 0s 593us/step - loss: 0.6356 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 93/100\n",
      "418/418 [==============================] - 0s 583us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 94/100\n",
      "418/418 [==============================] - 0s 592us/step - loss: 0.6369 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 95/100\n",
      "418/418 [==============================] - 0s 581us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 96/100\n",
      "418/418 [==============================] - 0s 598us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 97/100\n",
      "418/418 [==============================] - 0s 601us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 98/100\n",
      "418/418 [==============================] - 0s 593us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 99/100\n",
      "418/418 [==============================] - 0s 603us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 100/100\n",
      "418/418 [==============================] - 0s 588us/step - loss: 0.6357 - accuracy: 0.6679 - val_loss: 0.6367 - val_accuracy: 0.6664\n",
      "Epoch 1/100\n",
      "418/418 [==============================] - 0s 698us/step - loss: 0.5257 - accuracy: 0.8003 - val_loss: 0.5262 - val_accuracy: 0.7871\n",
      "Epoch 2/100\n",
      "418/418 [==============================] - 0s 597us/step - loss: 0.5072 - accuracy: 0.8003 - val_loss: 0.5191 - val_accuracy: 0.7871\n",
      "Epoch 3/100\n",
      "418/418 [==============================] - 0s 589us/step - loss: 0.5017 - accuracy: 0.8003 - val_loss: 0.5178 - val_accuracy: 0.7871\n",
      "Epoch 4/100\n",
      "418/418 [==============================] - 0s 596us/step - loss: 0.5003 - accuracy: 0.8003 - val_loss: 0.5180 - val_accuracy: 0.7871\n",
      "Epoch 5/100\n",
      "418/418 [==============================] - 0s 594us/step - loss: 0.5001 - accuracy: 0.8003 - val_loss: 0.5182 - val_accuracy: 0.7871\n",
      "Epoch 6/100\n",
      "418/418 [==============================] - 0s 592us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5184 - val_accuracy: 0.7871\n",
      "Epoch 7/100\n",
      "418/418 [==============================] - 0s 579us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5184 - val_accuracy: 0.7871\n",
      "Epoch 8/100\n",
      "418/418 [==============================] - 0s 576us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5184 - val_accuracy: 0.7871\n",
      "Epoch 9/100\n",
      "418/418 [==============================] - 0s 618us/step - loss: 0.5110 - accuracy: 0.8003 - val_loss: 0.5183 - val_accuracy: 0.7871\n",
      "Epoch 10/100\n",
      "418/418 [==============================] - 0s 579us/step - loss: 0.5005 - accuracy: 0.8002 - val_loss: 0.5183 - val_accuracy: 0.7871\n",
      "Epoch 11/100\n",
      "418/418 [==============================] - 0s 588us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5183 - val_accuracy: 0.7871\n",
      "Epoch 12/100\n",
      "418/418 [==============================] - 0s 598us/step - loss: 0.5002 - accuracy: 0.8002 - val_loss: 0.5183 - val_accuracy: 0.7871\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418/418 [==============================] - 0s 594us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5183 - val_accuracy: 0.7871\n",
      "Epoch 14/100\n",
      "418/418 [==============================] - 0s 582us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5183 - val_accuracy: 0.7871\n",
      "Epoch 15/100\n",
      "418/418 [==============================] - 0s 576us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5184 - val_accuracy: 0.7871\n",
      "Epoch 16/100\n",
      "418/418 [==============================] - 0s 573us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5183 - val_accuracy: 0.7871\n",
      "Epoch 17/100\n",
      "418/418 [==============================] - 0s 575us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5183 - val_accuracy: 0.7871\n",
      "Epoch 18/100\n",
      "418/418 [==============================] - 0s 578us/step - loss: 0.5002 - accuracy: 0.8003 - val_loss: 0.5183 - val_accuracy: 0.7871\n",
      "Epoch 19/100\n",
      "418/418 [==============================] - 0s 586us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5183 - val_accuracy: 0.7871\n",
      "Epoch 20/100\n",
      "418/418 [==============================] - 0s 589us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5183 - val_accuracy: 0.7871\n",
      "Epoch 21/100\n",
      "418/418 [==============================] - 0s 589us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5183 - val_accuracy: 0.7871\n",
      "Epoch 22/100\n",
      "418/418 [==============================] - 0s 589us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5184 - val_accuracy: 0.7871\n",
      "Epoch 23/100\n",
      "418/418 [==============================] - 0s 580us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5184 - val_accuracy: 0.7871\n",
      "Epoch 24/100\n",
      "418/418 [==============================] - 0s 581us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5184 - val_accuracy: 0.7871\n",
      "Epoch 25/100\n",
      "418/418 [==============================] - 0s 590us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5184 - val_accuracy: 0.7871\n",
      "Epoch 26/100\n",
      "418/418 [==============================] - 0s 576us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5183 - val_accuracy: 0.7871\n",
      "Epoch 27/100\n",
      "418/418 [==============================] - 0s 584us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5183 - val_accuracy: 0.7871\n",
      "Epoch 28/100\n",
      "418/418 [==============================] - 0s 592us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5183 - val_accuracy: 0.7871\n",
      "Epoch 29/100\n",
      "418/418 [==============================] - 0s 596us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5183 - val_accuracy: 0.7871\n",
      "Epoch 30/100\n",
      "418/418 [==============================] - 0s 588us/step - loss: 0.5001 - accuracy: 0.8003 - val_loss: 0.5183 - val_accuracy: 0.7871\n",
      "Epoch 31/100\n",
      "418/418 [==============================] - 0s 577us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5184 - val_accuracy: 0.7871\n",
      "Epoch 32/100\n",
      "418/418 [==============================] - 0s 592us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5183 - val_accuracy: 0.7871\n",
      "Epoch 33/100\n",
      "418/418 [==============================] - 0s 585us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5184 - val_accuracy: 0.7871\n",
      "Epoch 34/100\n",
      "418/418 [==============================] - 0s 591us/step - loss: 0.5001 - accuracy: 0.8003 - val_loss: 0.5184 - val_accuracy: 0.7871\n",
      "Epoch 35/100\n",
      "418/418 [==============================] - 0s 582us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5184 - val_accuracy: 0.7871\n",
      "Epoch 36/100\n",
      "418/418 [==============================] - 0s 589us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5184 - val_accuracy: 0.7871\n",
      "Epoch 37/100\n",
      "418/418 [==============================] - 0s 583us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5183 - val_accuracy: 0.7871\n",
      "Epoch 38/100\n",
      "418/418 [==============================] - 0s 586us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5184 - val_accuracy: 0.7871\n",
      "Epoch 39/100\n",
      "418/418 [==============================] - 0s 578us/step - loss: 0.5050 - accuracy: 0.8003 - val_loss: 0.5185 - val_accuracy: 0.7871\n",
      "Epoch 40/100\n",
      "418/418 [==============================] - 0s 572us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5183 - val_accuracy: 0.7871\n",
      "Epoch 41/100\n",
      "418/418 [==============================] - 0s 578us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5183 - val_accuracy: 0.7871\n",
      "Epoch 42/100\n",
      "418/418 [==============================] - 0s 580us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5183 - val_accuracy: 0.7871\n",
      "Epoch 43/100\n",
      "418/418 [==============================] - 0s 574us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5184 - val_accuracy: 0.7871\n",
      "Epoch 44/100\n",
      "418/418 [==============================] - 0s 579us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5183 - val_accuracy: 0.7871\n",
      "Epoch 45/100\n",
      "418/418 [==============================] - 0s 581us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5184 - val_accuracy: 0.7871\n",
      "Epoch 46/100\n",
      "418/418 [==============================] - 0s 575us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5183 - val_accuracy: 0.7871\n",
      "Epoch 47/100\n",
      "418/418 [==============================] - 0s 576us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5184 - val_accuracy: 0.7871\n",
      "Epoch 48/100\n",
      "418/418 [==============================] - 0s 571us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5183 - val_accuracy: 0.7871\n",
      "Epoch 49/100\n",
      "418/418 [==============================] - 0s 583us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5185 - val_accuracy: 0.7871\n",
      "Epoch 50/100\n",
      "418/418 [==============================] - 0s 579us/step - loss: 0.5001 - accuracy: 0.8003 - val_loss: 0.5184 - val_accuracy: 0.7871\n",
      "Epoch 51/100\n",
      "418/418 [==============================] - 0s 576us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5183 - val_accuracy: 0.7871\n",
      "Epoch 52/100\n",
      "418/418 [==============================] - 0s 574us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5183 - val_accuracy: 0.7871\n",
      "Epoch 53/100\n",
      "418/418 [==============================] - 0s 599us/step - loss: 0.5001 - accuracy: 0.8003 - val_loss: 0.5183 - val_accuracy: 0.7871\n",
      "Epoch 54/100\n",
      "418/418 [==============================] - 0s 599us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5184 - val_accuracy: 0.7871\n",
      "Epoch 55/100\n",
      "418/418 [==============================] - 0s 599us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5184 - val_accuracy: 0.7871\n",
      "Epoch 56/100\n",
      "418/418 [==============================] - 0s 589us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5184 - val_accuracy: 0.7871\n",
      "Epoch 57/100\n",
      "418/418 [==============================] - 0s 580us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5183 - val_accuracy: 0.7871\n",
      "Epoch 58/100\n",
      "418/418 [==============================] - 0s 583us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5183 - val_accuracy: 0.7871\n",
      "Epoch 59/100\n",
      "418/418 [==============================] - 0s 580us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5184 - val_accuracy: 0.7871\n",
      "Epoch 60/100\n",
      "418/418 [==============================] - 0s 610us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5183 - val_accuracy: 0.7871\n",
      "Epoch 61/100\n",
      "418/418 [==============================] - 0s 594us/step - loss: 0.5010 - accuracy: 0.8003 - val_loss: 0.5183 - val_accuracy: 0.7871\n",
      "Epoch 62/100\n",
      "418/418 [==============================] - 0s 603us/step - loss: 0.5002 - accuracy: 0.8003 - val_loss: 0.5183 - val_accuracy: 0.7871\n",
      "Epoch 63/100\n",
      "418/418 [==============================] - 0s 602us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5184 - val_accuracy: 0.7871\n",
      "Epoch 64/100\n",
      "418/418 [==============================] - 0s 598us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5183 - val_accuracy: 0.7871\n",
      "Epoch 65/100\n",
      "418/418 [==============================] - 0s 580us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5183 - val_accuracy: 0.7871\n",
      "Epoch 66/100\n",
      "418/418 [==============================] - 0s 575us/step - loss: 0.5001 - accuracy: 0.8003 - val_loss: 0.5183 - val_accuracy: 0.7871\n",
      "Epoch 67/100\n",
      "418/418 [==============================] - 0s 574us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5183 - val_accuracy: 0.7871\n",
      "Epoch 68/100\n",
      "418/418 [==============================] - 0s 571us/step - loss: 0.5008 - accuracy: 0.8003 - val_loss: 0.5183 - val_accuracy: 0.7871\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418/418 [==============================] - 0s 604us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5183 - val_accuracy: 0.7871\n",
      "Epoch 70/100\n",
      "418/418 [==============================] - 0s 606us/step - loss: 0.5011 - accuracy: 0.8002 - val_loss: 0.5183 - val_accuracy: 0.7871\n",
      "Epoch 71/100\n",
      "418/418 [==============================] - 0s 594us/step - loss: 0.5006 - accuracy: 0.8003 - val_loss: 0.5184 - val_accuracy: 0.7871\n",
      "Epoch 72/100\n",
      "418/418 [==============================] - 0s 570us/step - loss: 0.5003 - accuracy: 0.8003 - val_loss: 0.5183 - val_accuracy: 0.7871\n",
      "Epoch 73/100\n",
      "418/418 [==============================] - 0s 567us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5184 - val_accuracy: 0.7871\n",
      "Epoch 74/100\n",
      "418/418 [==============================] - 0s 569us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5184 - val_accuracy: 0.7871\n",
      "Epoch 75/100\n",
      "418/418 [==============================] - 0s 578us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5183 - val_accuracy: 0.7871\n",
      "Epoch 76/100\n",
      "418/418 [==============================] - 0s 590us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5183 - val_accuracy: 0.7871\n",
      "Epoch 77/100\n",
      "418/418 [==============================] - 0s 577us/step - loss: 0.5001 - accuracy: 0.8002 - val_loss: 0.5184 - val_accuracy: 0.7871\n",
      "Epoch 78/100\n",
      "418/418 [==============================] - 0s 573us/step - loss: 0.5003 - accuracy: 0.8002 - val_loss: 0.5184 - val_accuracy: 0.7871\n",
      "Epoch 79/100\n",
      "418/418 [==============================] - 0s 588us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5183 - val_accuracy: 0.7871\n",
      "Epoch 80/100\n",
      "418/418 [==============================] - 0s 591us/step - loss: 0.5006 - accuracy: 0.8002 - val_loss: 0.5183 - val_accuracy: 0.7871\n",
      "Epoch 81/100\n",
      "418/418 [==============================] - 0s 580us/step - loss: 0.5001 - accuracy: 0.8003 - val_loss: 0.5184 - val_accuracy: 0.7871\n",
      "Epoch 82/100\n",
      "418/418 [==============================] - 0s 589us/step - loss: 0.5001 - accuracy: 0.8003 - val_loss: 0.5183 - val_accuracy: 0.7871\n",
      "Epoch 83/100\n",
      "418/418 [==============================] - 0s 598us/step - loss: 0.5002 - accuracy: 0.8002 - val_loss: 0.5183 - val_accuracy: 0.7871\n",
      "Epoch 84/100\n",
      "418/418 [==============================] - 0s 596us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5183 - val_accuracy: 0.7871\n",
      "Epoch 85/100\n",
      "418/418 [==============================] - 0s 605us/step - loss: 0.5009 - accuracy: 0.8002 - val_loss: 0.5184 - val_accuracy: 0.7871\n",
      "Epoch 86/100\n",
      "418/418 [==============================] - 0s 575us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5184 - val_accuracy: 0.7871\n",
      "Epoch 87/100\n",
      "418/418 [==============================] - 0s 588us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5184 - val_accuracy: 0.7871\n",
      "Epoch 88/100\n",
      "418/418 [==============================] - 0s 593us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5182 - val_accuracy: 0.7871\n",
      "Epoch 89/100\n",
      "418/418 [==============================] - 0s 591us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5183 - val_accuracy: 0.7871\n",
      "Epoch 90/100\n",
      "418/418 [==============================] - 0s 575us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5183 - val_accuracy: 0.7871\n",
      "Epoch 91/100\n",
      "418/418 [==============================] - 0s 597us/step - loss: 0.5003 - accuracy: 0.8003 - val_loss: 0.5184 - val_accuracy: 0.7871\n",
      "Epoch 92/100\n",
      "418/418 [==============================] - 0s 606us/step - loss: 0.5001 - accuracy: 0.8003 - val_loss: 0.5184 - val_accuracy: 0.7871\n",
      "Epoch 93/100\n",
      "418/418 [==============================] - 0s 592us/step - loss: 0.5001 - accuracy: 0.8003 - val_loss: 0.5183 - val_accuracy: 0.7871\n",
      "Epoch 94/100\n",
      "418/418 [==============================] - 0s 577us/step - loss: 0.5103 - accuracy: 0.8003 - val_loss: 0.5181 - val_accuracy: 0.7871\n",
      "Epoch 95/100\n",
      "418/418 [==============================] - 0s 587us/step - loss: 0.5007 - accuracy: 0.8002 - val_loss: 0.5183 - val_accuracy: 0.7871\n",
      "Epoch 96/100\n",
      "418/418 [==============================] - 0s 582us/step - loss: 0.5001 - accuracy: 0.8003 - val_loss: 0.5183 - val_accuracy: 0.7871\n",
      "Epoch 97/100\n",
      "418/418 [==============================] - 0s 581us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5184 - val_accuracy: 0.7871\n",
      "Epoch 98/100\n",
      "418/418 [==============================] - 0s 583us/step - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.5184 - val_accuracy: 0.7871\n",
      "Epoch 99/100\n",
      "418/418 [==============================] - 0s 574us/step - loss: 0.5001 - accuracy: 0.8003 - val_loss: 0.5185 - val_accuracy: 0.7871\n",
      "Epoch 100/100\n",
      "418/418 [==============================] - 0s 584us/step - loss: 0.5001 - accuracy: 0.8003 - val_loss: 0.5184 - val_accuracy: 0.7871\n",
      "310/310 [==============================] - 0s 262us/step\n",
      "310/310 [==============================] - 0s 251us/step\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(31,), activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model1 = model2 = model\n",
    "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model1.fit(X_train, EC1_train, epochs=100, batch_size=32, validation_split=0.1)\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model2.fit(X_train, EC2_train, epochs=100, batch_size=32, validation_split=0.1)\n",
    "EC1_pred = model1.predict(X_test)\n",
    "EC2_pred = model2.predict(X_test)\n",
    "\n",
    "df_samp['EC1'] = EC1_pred\n",
    "df_samp['EC2'] = EC2_pred\n",
    "\n",
    "df_samp.to_csv('submission2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b6e2710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 1.1249 - accuracy: 0.6406 - val_loss: 0.8277 - val_accuracy: 0.6051\n",
      "Epoch 2/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6425 - accuracy: 0.6768 - val_loss: 0.6128 - val_accuracy: 0.6900\n",
      "Epoch 3/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6192 - accuracy: 0.6777 - val_loss: 0.6140 - val_accuracy: 0.6631\n",
      "Epoch 4/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5985 - accuracy: 0.6891 - val_loss: 0.6177 - val_accuracy: 0.6867\n",
      "Epoch 5/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5881 - accuracy: 0.6953 - val_loss: 0.6061 - val_accuracy: 0.6853\n",
      "Epoch 6/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5863 - accuracy: 0.6940 - val_loss: 0.6097 - val_accuracy: 0.6624\n",
      "Epoch 7/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5856 - accuracy: 0.6946 - val_loss: 0.6045 - val_accuracy: 0.6867\n",
      "Epoch 8/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5862 - accuracy: 0.6922 - val_loss: 0.5990 - val_accuracy: 0.6806\n",
      "Epoch 9/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5836 - accuracy: 0.6957 - val_loss: 0.5983 - val_accuracy: 0.6772\n",
      "Epoch 10/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5815 - accuracy: 0.6982 - val_loss: 0.6003 - val_accuracy: 0.6712\n",
      "Epoch 11/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5833 - accuracy: 0.6969 - val_loss: 0.6047 - val_accuracy: 0.6840\n",
      "Epoch 12/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5820 - accuracy: 0.6982 - val_loss: 0.6049 - val_accuracy: 0.6745\n",
      "Epoch 13/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5801 - accuracy: 0.6992 - val_loss: 0.5994 - val_accuracy: 0.6799\n",
      "Epoch 14/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5814 - accuracy: 0.6958 - val_loss: 0.5988 - val_accuracy: 0.6732\n",
      "Epoch 15/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5785 - accuracy: 0.7021 - val_loss: 0.5951 - val_accuracy: 0.6887\n",
      "Epoch 16/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5784 - accuracy: 0.7018 - val_loss: 0.5968 - val_accuracy: 0.6792\n",
      "Epoch 17/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5792 - accuracy: 0.6971 - val_loss: 0.5985 - val_accuracy: 0.6792\n",
      "Epoch 18/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5765 - accuracy: 0.7044 - val_loss: 0.5961 - val_accuracy: 0.6873\n",
      "Epoch 19/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5758 - accuracy: 0.7018 - val_loss: 0.5988 - val_accuracy: 0.6894\n",
      "Epoch 20/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5769 - accuracy: 0.7022 - val_loss: 0.6001 - val_accuracy: 0.6799\n",
      "Epoch 21/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5778 - accuracy: 0.7046 - val_loss: 0.5985 - val_accuracy: 0.6792\n",
      "Epoch 22/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5785 - accuracy: 0.7026 - val_loss: 0.6025 - val_accuracy: 0.6867\n",
      "Epoch 23/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5754 - accuracy: 0.7023 - val_loss: 0.6030 - val_accuracy: 0.6941\n",
      "Epoch 24/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5766 - accuracy: 0.7024 - val_loss: 0.6040 - val_accuracy: 0.6833\n",
      "Epoch 25/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5740 - accuracy: 0.7052 - val_loss: 0.6013 - val_accuracy: 0.6900\n",
      "Epoch 26/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5736 - accuracy: 0.7030 - val_loss: 0.5956 - val_accuracy: 0.6914\n",
      "Epoch 27/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5732 - accuracy: 0.7083 - val_loss: 0.6022 - val_accuracy: 0.6894\n",
      "Epoch 28/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5729 - accuracy: 0.7065 - val_loss: 0.5982 - val_accuracy: 0.6947\n",
      "Epoch 29/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5714 - accuracy: 0.7055 - val_loss: 0.6050 - val_accuracy: 0.6927\n",
      "Epoch 30/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5730 - accuracy: 0.7055 - val_loss: 0.6216 - val_accuracy: 0.6867\n",
      "Epoch 31/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5707 - accuracy: 0.7053 - val_loss: 0.6038 - val_accuracy: 0.6961\n",
      "Epoch 32/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5700 - accuracy: 0.7090 - val_loss: 0.6115 - val_accuracy: 0.6833\n",
      "Epoch 33/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5696 - accuracy: 0.7074 - val_loss: 0.6049 - val_accuracy: 0.6947\n",
      "Epoch 34/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5690 - accuracy: 0.7095 - val_loss: 0.6023 - val_accuracy: 0.6880\n",
      "Epoch 35/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5680 - accuracy: 0.7120 - val_loss: 0.6076 - val_accuracy: 0.6880\n",
      "Epoch 36/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5680 - accuracy: 0.7094 - val_loss: 0.6073 - val_accuracy: 0.6867\n",
      "Epoch 37/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5687 - accuracy: 0.7110 - val_loss: 0.6074 - val_accuracy: 0.6873\n",
      "Epoch 38/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5666 - accuracy: 0.7077 - val_loss: 0.6069 - val_accuracy: 0.6914\n",
      "Epoch 39/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5661 - accuracy: 0.7094 - val_loss: 0.6090 - val_accuracy: 0.6894\n",
      "Epoch 40/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5653 - accuracy: 0.7109 - val_loss: 0.6073 - val_accuracy: 0.6914\n",
      "Epoch 41/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5653 - accuracy: 0.7078 - val_loss: 0.6127 - val_accuracy: 0.6907\n",
      "Epoch 42/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5647 - accuracy: 0.7091 - val_loss: 0.6175 - val_accuracy: 0.6873\n",
      "Epoch 43/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5629 - accuracy: 0.7113 - val_loss: 0.6145 - val_accuracy: 0.6920\n",
      "Epoch 44/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5619 - accuracy: 0.7123 - val_loss: 0.6167 - val_accuracy: 0.6927\n",
      "Epoch 45/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5617 - accuracy: 0.7135 - val_loss: 0.6146 - val_accuracy: 0.6873\n",
      "Epoch 46/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5602 - accuracy: 0.7110 - val_loss: 0.6338 - val_accuracy: 0.6759\n",
      "Epoch 47/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5606 - accuracy: 0.7132 - val_loss: 0.6194 - val_accuracy: 0.6900\n",
      "Epoch 48/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5592 - accuracy: 0.7112 - val_loss: 0.6074 - val_accuracy: 0.6860\n",
      "Epoch 49/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5570 - accuracy: 0.7148 - val_loss: 0.6296 - val_accuracy: 0.6860\n",
      "Epoch 50/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5560 - accuracy: 0.7151 - val_loss: 0.6345 - val_accuracy: 0.6867\n",
      "Epoch 51/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5545 - accuracy: 0.7157 - val_loss: 0.6308 - val_accuracy: 0.6846\n",
      "Epoch 52/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5531 - accuracy: 0.7151 - val_loss: 0.6365 - val_accuracy: 0.6806\n",
      "Epoch 53/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5517 - accuracy: 0.7205 - val_loss: 0.6456 - val_accuracy: 0.6739\n",
      "Epoch 54/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5507 - accuracy: 0.7188 - val_loss: 0.6377 - val_accuracy: 0.6765\n",
      "Epoch 55/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5492 - accuracy: 0.7208 - val_loss: 0.6328 - val_accuracy: 0.6739\n",
      "Epoch 56/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5470 - accuracy: 0.7219 - val_loss: 0.6406 - val_accuracy: 0.6772\n",
      "Epoch 57/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5476 - accuracy: 0.7209 - val_loss: 0.6557 - val_accuracy: 0.6819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5429 - accuracy: 0.7234 - val_loss: 0.6425 - val_accuracy: 0.6840\n",
      "Epoch 59/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5420 - accuracy: 0.7243 - val_loss: 0.6554 - val_accuracy: 0.6759\n",
      "Epoch 60/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5383 - accuracy: 0.7240 - val_loss: 0.6476 - val_accuracy: 0.6752\n",
      "Epoch 61/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5392 - accuracy: 0.7272 - val_loss: 0.6630 - val_accuracy: 0.6739\n",
      "Epoch 62/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5358 - accuracy: 0.7259 - val_loss: 0.6632 - val_accuracy: 0.6671\n",
      "Epoch 63/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5332 - accuracy: 0.7309 - val_loss: 0.6759 - val_accuracy: 0.6691\n",
      "Epoch 64/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5311 - accuracy: 0.7298 - val_loss: 0.6781 - val_accuracy: 0.6779\n",
      "Epoch 65/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5316 - accuracy: 0.7322 - val_loss: 0.6866 - val_accuracy: 0.6752\n",
      "Epoch 66/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5274 - accuracy: 0.7279 - val_loss: 0.6919 - val_accuracy: 0.6712\n",
      "Epoch 67/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5230 - accuracy: 0.7351 - val_loss: 0.6926 - val_accuracy: 0.6671\n",
      "Epoch 68/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5223 - accuracy: 0.7369 - val_loss: 0.6788 - val_accuracy: 0.6752\n",
      "Epoch 69/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5185 - accuracy: 0.7384 - val_loss: 0.7202 - val_accuracy: 0.6705\n",
      "Epoch 70/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5173 - accuracy: 0.7371 - val_loss: 0.7186 - val_accuracy: 0.6611\n",
      "Epoch 71/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5140 - accuracy: 0.7396 - val_loss: 0.7597 - val_accuracy: 0.6570\n",
      "Epoch 72/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5137 - accuracy: 0.7410 - val_loss: 0.7464 - val_accuracy: 0.6765\n",
      "Epoch 73/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5084 - accuracy: 0.7442 - val_loss: 0.7743 - val_accuracy: 0.6691\n",
      "Epoch 74/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5060 - accuracy: 0.7432 - val_loss: 0.7685 - val_accuracy: 0.6584\n",
      "Epoch 75/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5031 - accuracy: 0.7491 - val_loss: 0.7607 - val_accuracy: 0.6604\n",
      "Epoch 76/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5008 - accuracy: 0.7501 - val_loss: 0.7708 - val_accuracy: 0.6752\n",
      "Epoch 77/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4987 - accuracy: 0.7475 - val_loss: 0.7713 - val_accuracy: 0.6664\n",
      "Epoch 78/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4972 - accuracy: 0.7514 - val_loss: 0.7848 - val_accuracy: 0.6631\n",
      "Epoch 79/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4892 - accuracy: 0.7551 - val_loss: 0.8083 - val_accuracy: 0.6698\n",
      "Epoch 80/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4895 - accuracy: 0.7551 - val_loss: 0.7864 - val_accuracy: 0.6530\n",
      "Epoch 81/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4881 - accuracy: 0.7518 - val_loss: 0.8155 - val_accuracy: 0.6597\n",
      "Epoch 82/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4862 - accuracy: 0.7554 - val_loss: 0.8060 - val_accuracy: 0.6611\n",
      "Epoch 83/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4817 - accuracy: 0.7598 - val_loss: 0.8050 - val_accuracy: 0.6543\n",
      "Epoch 84/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4771 - accuracy: 0.7631 - val_loss: 0.8409 - val_accuracy: 0.6543\n",
      "Epoch 85/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4753 - accuracy: 0.7638 - val_loss: 0.8441 - val_accuracy: 0.6476\n",
      "Epoch 86/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4739 - accuracy: 0.7643 - val_loss: 0.8422 - val_accuracy: 0.6590\n",
      "Epoch 87/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4704 - accuracy: 0.7670 - val_loss: 0.8619 - val_accuracy: 0.6563\n",
      "Epoch 88/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4669 - accuracy: 0.7668 - val_loss: 0.8620 - val_accuracy: 0.6469\n",
      "Epoch 89/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4659 - accuracy: 0.7683 - val_loss: 0.8666 - val_accuracy: 0.6429\n",
      "Epoch 90/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4615 - accuracy: 0.7687 - val_loss: 0.8688 - val_accuracy: 0.6577\n",
      "Epoch 91/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4612 - accuracy: 0.7715 - val_loss: 0.8929 - val_accuracy: 0.6482\n",
      "Epoch 92/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4556 - accuracy: 0.7768 - val_loss: 0.9060 - val_accuracy: 0.6570\n",
      "Epoch 93/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4590 - accuracy: 0.7726 - val_loss: 0.9082 - val_accuracy: 0.6503\n",
      "Epoch 94/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4517 - accuracy: 0.7785 - val_loss: 0.9299 - val_accuracy: 0.6563\n",
      "Epoch 95/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4455 - accuracy: 0.7813 - val_loss: 0.9833 - val_accuracy: 0.6503\n",
      "Epoch 96/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4472 - accuracy: 0.7803 - val_loss: 0.9730 - val_accuracy: 0.6516\n",
      "Epoch 97/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4423 - accuracy: 0.7816 - val_loss: 0.9527 - val_accuracy: 0.6240\n",
      "Epoch 98/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4393 - accuracy: 0.7843 - val_loss: 1.0141 - val_accuracy: 0.6503\n",
      "Epoch 99/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4433 - accuracy: 0.7780 - val_loss: 0.9934 - val_accuracy: 0.6523\n",
      "Epoch 100/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4357 - accuracy: 0.7861 - val_loss: 0.9865 - val_accuracy: 0.6415\n",
      "Epoch 1/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6047 - accuracy: 0.7696 - val_loss: 0.5527 - val_accuracy: 0.7810\n",
      "Epoch 2/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5116 - accuracy: 0.7947 - val_loss: 0.5278 - val_accuracy: 0.7884\n",
      "Epoch 3/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5000 - accuracy: 0.8004 - val_loss: 0.5323 - val_accuracy: 0.7871\n",
      "Epoch 4/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4998 - accuracy: 0.7983 - val_loss: 0.5302 - val_accuracy: 0.7877\n",
      "Epoch 5/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4921 - accuracy: 0.8013 - val_loss: 0.5221 - val_accuracy: 0.7850\n",
      "Epoch 6/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4891 - accuracy: 0.8012 - val_loss: 0.5261 - val_accuracy: 0.7864\n",
      "Epoch 7/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4886 - accuracy: 0.8011 - val_loss: 0.5222 - val_accuracy: 0.7871\n",
      "Epoch 8/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4848 - accuracy: 0.8010 - val_loss: 0.5217 - val_accuracy: 0.7857\n",
      "Epoch 9/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4831 - accuracy: 0.8021 - val_loss: 0.5247 - val_accuracy: 0.7871\n",
      "Epoch 10/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4857 - accuracy: 0.8010 - val_loss: 0.5259 - val_accuracy: 0.7898\n",
      "Epoch 11/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4819 - accuracy: 0.8014 - val_loss: 0.5206 - val_accuracy: 0.7857\n",
      "Epoch 12/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4780 - accuracy: 0.8030 - val_loss: 0.5238 - val_accuracy: 0.7871\n",
      "Epoch 13/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4752 - accuracy: 0.8029 - val_loss: 0.5323 - val_accuracy: 0.7871\n",
      "Epoch 14/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4747 - accuracy: 0.8028 - val_loss: 0.5270 - val_accuracy: 0.7864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4741 - accuracy: 0.8043 - val_loss: 0.5214 - val_accuracy: 0.7877\n",
      "Epoch 16/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4728 - accuracy: 0.8042 - val_loss: 0.5252 - val_accuracy: 0.7837\n",
      "Epoch 17/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4704 - accuracy: 0.8039 - val_loss: 0.5397 - val_accuracy: 0.7857\n",
      "Epoch 18/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4700 - accuracy: 0.8054 - val_loss: 0.5339 - val_accuracy: 0.7830\n",
      "Epoch 19/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4671 - accuracy: 0.8062 - val_loss: 0.5359 - val_accuracy: 0.7803\n",
      "Epoch 20/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4640 - accuracy: 0.8072 - val_loss: 0.5430 - val_accuracy: 0.7823\n",
      "Epoch 21/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4609 - accuracy: 0.8078 - val_loss: 0.5409 - val_accuracy: 0.7790\n",
      "Epoch 22/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4604 - accuracy: 0.8087 - val_loss: 0.5443 - val_accuracy: 0.7864\n",
      "Epoch 23/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4582 - accuracy: 0.8082 - val_loss: 0.5465 - val_accuracy: 0.7763\n",
      "Epoch 24/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4594 - accuracy: 0.8072 - val_loss: 0.5537 - val_accuracy: 0.7790\n",
      "Epoch 25/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4590 - accuracy: 0.8083 - val_loss: 0.5461 - val_accuracy: 0.7830\n",
      "Epoch 26/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4543 - accuracy: 0.8087 - val_loss: 0.5538 - val_accuracy: 0.7716\n",
      "Epoch 27/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4523 - accuracy: 0.8103 - val_loss: 0.5647 - val_accuracy: 0.7763\n",
      "Epoch 28/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4492 - accuracy: 0.8124 - val_loss: 0.5571 - val_accuracy: 0.7736\n",
      "Epoch 29/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4481 - accuracy: 0.8111 - val_loss: 0.5677 - val_accuracy: 0.7743\n",
      "Epoch 30/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4441 - accuracy: 0.8129 - val_loss: 0.5775 - val_accuracy: 0.7743\n",
      "Epoch 31/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4417 - accuracy: 0.8151 - val_loss: 0.5830 - val_accuracy: 0.7648\n",
      "Epoch 32/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4411 - accuracy: 0.8145 - val_loss: 0.5834 - val_accuracy: 0.7790\n",
      "Epoch 33/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4416 - accuracy: 0.8153 - val_loss: 0.5817 - val_accuracy: 0.7689\n",
      "Epoch 34/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4361 - accuracy: 0.8156 - val_loss: 0.6057 - val_accuracy: 0.7668\n",
      "Epoch 35/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4356 - accuracy: 0.8161 - val_loss: 0.6062 - val_accuracy: 0.7716\n",
      "Epoch 36/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4329 - accuracy: 0.8170 - val_loss: 0.6043 - val_accuracy: 0.7770\n",
      "Epoch 37/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4335 - accuracy: 0.8194 - val_loss: 0.6242 - val_accuracy: 0.7749\n",
      "Epoch 38/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4364 - accuracy: 0.8156 - val_loss: 0.5938 - val_accuracy: 0.7709\n",
      "Epoch 39/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4282 - accuracy: 0.8204 - val_loss: 0.6083 - val_accuracy: 0.7743\n",
      "Epoch 40/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4307 - accuracy: 0.8193 - val_loss: 0.6057 - val_accuracy: 0.7736\n",
      "Epoch 41/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4240 - accuracy: 0.8207 - val_loss: 0.6141 - val_accuracy: 0.7662\n",
      "Epoch 42/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4244 - accuracy: 0.8205 - val_loss: 0.6122 - val_accuracy: 0.7709\n",
      "Epoch 43/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4215 - accuracy: 0.8212 - val_loss: 0.6255 - val_accuracy: 0.7662\n",
      "Epoch 44/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4188 - accuracy: 0.8227 - val_loss: 0.6268 - val_accuracy: 0.7594\n",
      "Epoch 45/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4183 - accuracy: 0.8227 - val_loss: 0.6266 - val_accuracy: 0.7648\n",
      "Epoch 46/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4162 - accuracy: 0.8235 - val_loss: 0.6096 - val_accuracy: 0.7648\n",
      "Epoch 47/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4138 - accuracy: 0.8253 - val_loss: 0.6339 - val_accuracy: 0.7689\n",
      "Epoch 48/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4123 - accuracy: 0.8255 - val_loss: 0.6491 - val_accuracy: 0.7534\n",
      "Epoch 49/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4110 - accuracy: 0.8264 - val_loss: 0.6062 - val_accuracy: 0.7642\n",
      "Epoch 50/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4097 - accuracy: 0.8262 - val_loss: 0.6526 - val_accuracy: 0.7729\n",
      "Epoch 51/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4074 - accuracy: 0.8271 - val_loss: 0.6586 - val_accuracy: 0.7608\n",
      "Epoch 52/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4063 - accuracy: 0.8287 - val_loss: 0.6453 - val_accuracy: 0.7628\n",
      "Epoch 53/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4077 - accuracy: 0.8275 - val_loss: 0.6626 - val_accuracy: 0.7574\n",
      "Epoch 54/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4031 - accuracy: 0.8286 - val_loss: 0.6721 - val_accuracy: 0.7668\n",
      "Epoch 55/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4043 - accuracy: 0.8277 - val_loss: 0.6556 - val_accuracy: 0.7635\n",
      "Epoch 56/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4226 - accuracy: 0.8273 - val_loss: 0.6677 - val_accuracy: 0.7561\n",
      "Epoch 57/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4085 - accuracy: 0.8296 - val_loss: 0.6840 - val_accuracy: 0.7655\n",
      "Epoch 58/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4013 - accuracy: 0.8307 - val_loss: 0.6786 - val_accuracy: 0.7615\n",
      "Epoch 59/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.4013 - accuracy: 0.8303 - val_loss: 0.6809 - val_accuracy: 0.7675\n",
      "Epoch 60/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.3971 - accuracy: 0.8311 - val_loss: 0.6905 - val_accuracy: 0.7648\n",
      "Epoch 61/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.3948 - accuracy: 0.8329 - val_loss: 0.6973 - val_accuracy: 0.7642\n",
      "Epoch 62/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.3985 - accuracy: 0.8327 - val_loss: 0.6725 - val_accuracy: 0.7621\n",
      "Epoch 63/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.3945 - accuracy: 0.8347 - val_loss: 0.6697 - val_accuracy: 0.7722\n",
      "Epoch 64/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.3916 - accuracy: 0.8341 - val_loss: 0.6773 - val_accuracy: 0.7608\n",
      "Epoch 65/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.3919 - accuracy: 0.8326 - val_loss: 0.6817 - val_accuracy: 0.7642\n",
      "Epoch 66/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.3900 - accuracy: 0.8342 - val_loss: 0.6601 - val_accuracy: 0.7527\n",
      "Epoch 67/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.3881 - accuracy: 0.8355 - val_loss: 0.6826 - val_accuracy: 0.7621\n",
      "Epoch 68/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.3916 - accuracy: 0.8328 - val_loss: 0.6744 - val_accuracy: 0.7709\n",
      "Epoch 69/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.3887 - accuracy: 0.8394 - val_loss: 0.7131 - val_accuracy: 0.7507\n",
      "Epoch 70/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.3860 - accuracy: 0.8342 - val_loss: 0.6785 - val_accuracy: 0.7668\n",
      "Epoch 71/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.3862 - accuracy: 0.8373 - val_loss: 0.7142 - val_accuracy: 0.7581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.3827 - accuracy: 0.8391 - val_loss: 0.7074 - val_accuracy: 0.7547\n",
      "Epoch 73/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.3881 - accuracy: 0.8358 - val_loss: 0.6888 - val_accuracy: 0.7615\n",
      "Epoch 74/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.3816 - accuracy: 0.8405 - val_loss: 0.7266 - val_accuracy: 0.7487\n",
      "Epoch 75/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.3773 - accuracy: 0.8399 - val_loss: 0.7133 - val_accuracy: 0.7662\n",
      "Epoch 76/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.3855 - accuracy: 0.8393 - val_loss: 0.7445 - val_accuracy: 0.7534\n",
      "Epoch 77/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.3768 - accuracy: 0.8386 - val_loss: 0.7216 - val_accuracy: 0.7615\n",
      "Epoch 78/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.3798 - accuracy: 0.8377 - val_loss: 0.7618 - val_accuracy: 0.7668\n",
      "Epoch 79/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.3767 - accuracy: 0.8408 - val_loss: 0.7449 - val_accuracy: 0.7662\n",
      "Epoch 80/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.3815 - accuracy: 0.8394 - val_loss: 0.7423 - val_accuracy: 0.7520\n",
      "Epoch 81/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.3764 - accuracy: 0.8397 - val_loss: 0.7470 - val_accuracy: 0.7621\n",
      "Epoch 82/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.3728 - accuracy: 0.8421 - val_loss: 0.7304 - val_accuracy: 0.7439\n",
      "Epoch 83/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.3709 - accuracy: 0.8433 - val_loss: 0.7452 - val_accuracy: 0.7608\n",
      "Epoch 84/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.3692 - accuracy: 0.8424 - val_loss: 0.7593 - val_accuracy: 0.7379\n",
      "Epoch 85/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.3695 - accuracy: 0.8433 - val_loss: 0.7534 - val_accuracy: 0.7493\n",
      "Epoch 86/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.3711 - accuracy: 0.8437 - val_loss: 0.7729 - val_accuracy: 0.7379\n",
      "Epoch 87/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.3713 - accuracy: 0.8422 - val_loss: 0.7369 - val_accuracy: 0.7412\n",
      "Epoch 88/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.3727 - accuracy: 0.8457 - val_loss: 0.7690 - val_accuracy: 0.7446\n",
      "Epoch 89/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.3669 - accuracy: 0.8456 - val_loss: 0.7596 - val_accuracy: 0.7466\n",
      "Epoch 90/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.3673 - accuracy: 0.8427 - val_loss: 0.7776 - val_accuracy: 0.7392\n",
      "Epoch 91/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.3604 - accuracy: 0.8475 - val_loss: 0.7587 - val_accuracy: 0.7487\n",
      "Epoch 92/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.3620 - accuracy: 0.8474 - val_loss: 0.7595 - val_accuracy: 0.7480\n",
      "Epoch 93/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.3627 - accuracy: 0.8449 - val_loss: 0.7999 - val_accuracy: 0.7628\n",
      "Epoch 94/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.3621 - accuracy: 0.8478 - val_loss: 0.7987 - val_accuracy: 0.7439\n",
      "Epoch 95/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.3633 - accuracy: 0.8457 - val_loss: 0.7638 - val_accuracy: 0.7588\n",
      "Epoch 96/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.3585 - accuracy: 0.8494 - val_loss: 0.7410 - val_accuracy: 0.7446\n",
      "Epoch 97/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.3582 - accuracy: 0.8493 - val_loss: 0.7798 - val_accuracy: 0.7338\n",
      "Epoch 98/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.3588 - accuracy: 0.8502 - val_loss: 0.7926 - val_accuracy: 0.7460\n",
      "Epoch 99/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.3604 - accuracy: 0.8452 - val_loss: 0.7961 - val_accuracy: 0.7493\n",
      "Epoch 100/100\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.3645 - accuracy: 0.8475 - val_loss: 0.8139 - val_accuracy: 0.7567\n",
      "310/310 [==============================] - 0s 458us/step\n",
      "310/310 [==============================] - 0s 449us/step\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(64, 3, activation='relu', input_shape=(31,1)))  \n",
    "model.add(MaxPooling1D(2))  \n",
    "model.add(Conv1D(64, 3, activation='relu')) \n",
    "model.add(MaxPooling1D(2))  \n",
    "model.add(Flatten()) \n",
    "model.add(Dense(128, activation='relu')) \n",
    "model.add(Dense(1, activation='sigmoid')) \n",
    "\n",
    "model1 = model2 = model\n",
    "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model1.fit(X_train, EC1_train, epochs=100, batch_size=32, validation_split=0.1)\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model2.fit(X_train, EC2_train, epochs=100, batch_size=32, validation_split=0.1)\n",
    "EC1_pred = model1.predict(X_test)\n",
    "EC2_pred = model2.predict(X_test)\n",
    "\n",
    "df_samp['EC1'] = EC1_pred\n",
    "df_samp['EC2'] = EC2_pred\n",
    "\n",
    "df_samp.to_csv('submission2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "712da51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.7729 - accuracy: 0.6502 - val_loss: 0.6371 - val_accuracy: 0.6752\n",
      "Epoch 2/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.6118 - accuracy: 0.6808 - val_loss: 0.6141 - val_accuracy: 0.6833\n",
      "Epoch 3/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5918 - accuracy: 0.6901 - val_loss: 0.6055 - val_accuracy: 0.6813\n",
      "Epoch 4/100\n",
      "835/835 [==============================] - 1s 999us/step - loss: 0.5914 - accuracy: 0.6880 - val_loss: 0.5989 - val_accuracy: 0.6792\n",
      "Epoch 5/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5860 - accuracy: 0.6945 - val_loss: 0.6140 - val_accuracy: 0.6637\n",
      "Epoch 6/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5852 - accuracy: 0.6925 - val_loss: 0.5993 - val_accuracy: 0.6819\n",
      "Epoch 7/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5820 - accuracy: 0.6989 - val_loss: 0.5978 - val_accuracy: 0.6995\n",
      "Epoch 8/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5829 - accuracy: 0.6978 - val_loss: 0.6023 - val_accuracy: 0.6860\n",
      "Epoch 9/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5811 - accuracy: 0.6999 - val_loss: 0.5986 - val_accuracy: 0.6826\n",
      "Epoch 10/100\n",
      "835/835 [==============================] - 1s 989us/step - loss: 0.5806 - accuracy: 0.6987 - val_loss: 0.6028 - val_accuracy: 0.6894\n",
      "Epoch 11/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5805 - accuracy: 0.7012 - val_loss: 0.5974 - val_accuracy: 0.6833\n",
      "Epoch 12/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5783 - accuracy: 0.7015 - val_loss: 0.5930 - val_accuracy: 0.6772\n",
      "Epoch 13/100\n",
      "835/835 [==============================] - 1s 999us/step - loss: 0.5798 - accuracy: 0.6990 - val_loss: 0.6020 - val_accuracy: 0.6799\n",
      "Epoch 14/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5787 - accuracy: 0.6987 - val_loss: 0.5970 - val_accuracy: 0.6914\n",
      "Epoch 15/100\n",
      "835/835 [==============================] - 1s 984us/step - loss: 0.5767 - accuracy: 0.7031 - val_loss: 0.5994 - val_accuracy: 0.6813\n",
      "Epoch 16/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5752 - accuracy: 0.7022 - val_loss: 0.6043 - val_accuracy: 0.6873\n",
      "Epoch 17/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5747 - accuracy: 0.7068 - val_loss: 0.6060 - val_accuracy: 0.6867\n",
      "Epoch 18/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5732 - accuracy: 0.7062 - val_loss: 0.5980 - val_accuracy: 0.6887\n",
      "Epoch 19/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5733 - accuracy: 0.7077 - val_loss: 0.5983 - val_accuracy: 0.6880\n",
      "Epoch 20/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5709 - accuracy: 0.7083 - val_loss: 0.6026 - val_accuracy: 0.6887\n",
      "Epoch 21/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5717 - accuracy: 0.7061 - val_loss: 0.6110 - val_accuracy: 0.6934\n",
      "Epoch 22/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5700 - accuracy: 0.7056 - val_loss: 0.5996 - val_accuracy: 0.6860\n",
      "Epoch 23/100\n",
      "835/835 [==============================] - 1s 997us/step - loss: 0.5683 - accuracy: 0.7065 - val_loss: 0.6008 - val_accuracy: 0.6894\n",
      "Epoch 24/100\n",
      "835/835 [==============================] - 1s 991us/step - loss: 0.5671 - accuracy: 0.7118 - val_loss: 0.6005 - val_accuracy: 0.6941\n",
      "Epoch 25/100\n",
      "835/835 [==============================] - 1s 975us/step - loss: 0.5664 - accuracy: 0.7108 - val_loss: 0.6031 - val_accuracy: 0.6880\n",
      "Epoch 26/100\n",
      "835/835 [==============================] - 1s 997us/step - loss: 0.5640 - accuracy: 0.7122 - val_loss: 0.6014 - val_accuracy: 0.6880\n",
      "Epoch 27/100\n",
      "835/835 [==============================] - 1s 993us/step - loss: 0.5630 - accuracy: 0.7165 - val_loss: 0.6116 - val_accuracy: 0.6799\n",
      "Epoch 28/100\n",
      "835/835 [==============================] - 1s 993us/step - loss: 0.5607 - accuracy: 0.7157 - val_loss: 0.6131 - val_accuracy: 0.6840\n",
      "Epoch 29/100\n",
      "835/835 [==============================] - 1s 989us/step - loss: 0.5602 - accuracy: 0.7144 - val_loss: 0.6244 - val_accuracy: 0.6846\n",
      "Epoch 30/100\n",
      "835/835 [==============================] - 1s 977us/step - loss: 0.5578 - accuracy: 0.7181 - val_loss: 0.6172 - val_accuracy: 0.6853\n",
      "Epoch 31/100\n",
      "835/835 [==============================] - 1s 981us/step - loss: 0.5576 - accuracy: 0.7178 - val_loss: 0.6292 - val_accuracy: 0.6806\n",
      "Epoch 32/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5555 - accuracy: 0.7205 - val_loss: 0.6224 - val_accuracy: 0.6819\n",
      "Epoch 33/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5515 - accuracy: 0.7228 - val_loss: 0.6283 - val_accuracy: 0.6772\n",
      "Epoch 34/100\n",
      "835/835 [==============================] - 1s 998us/step - loss: 0.5504 - accuracy: 0.7231 - val_loss: 0.6388 - val_accuracy: 0.6745\n",
      "Epoch 35/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5496 - accuracy: 0.7244 - val_loss: 0.6329 - val_accuracy: 0.6745\n",
      "Epoch 36/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5458 - accuracy: 0.7283 - val_loss: 0.6313 - val_accuracy: 0.6745\n",
      "Epoch 37/100\n",
      "835/835 [==============================] - 1s 996us/step - loss: 0.5419 - accuracy: 0.7271 - val_loss: 0.6469 - val_accuracy: 0.6772\n",
      "Epoch 38/100\n",
      "835/835 [==============================] - 1s 995us/step - loss: 0.5408 - accuracy: 0.7310 - val_loss: 0.6379 - val_accuracy: 0.6752\n",
      "Epoch 39/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5373 - accuracy: 0.7341 - val_loss: 0.6416 - val_accuracy: 0.6867\n",
      "Epoch 40/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5332 - accuracy: 0.7356 - val_loss: 0.6851 - val_accuracy: 0.6792\n",
      "Epoch 41/100\n",
      "835/835 [==============================] - 1s 989us/step - loss: 0.5315 - accuracy: 0.7351 - val_loss: 0.6870 - val_accuracy: 0.6799\n",
      "Epoch 42/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5272 - accuracy: 0.7369 - val_loss: 0.6912 - val_accuracy: 0.6752\n",
      "Epoch 43/100\n",
      "835/835 [==============================] - 1s 997us/step - loss: 0.5260 - accuracy: 0.7368 - val_loss: 0.6914 - val_accuracy: 0.6624\n",
      "Epoch 44/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5194 - accuracy: 0.7401 - val_loss: 0.7463 - val_accuracy: 0.6759\n",
      "Epoch 45/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5159 - accuracy: 0.7469 - val_loss: 0.7567 - val_accuracy: 0.6489\n",
      "Epoch 46/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5145 - accuracy: 0.7449 - val_loss: 0.7725 - val_accuracy: 0.6590\n",
      "Epoch 47/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5060 - accuracy: 0.7469 - val_loss: 0.7597 - val_accuracy: 0.6577\n",
      "Epoch 48/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5019 - accuracy: 0.7513 - val_loss: 0.7699 - val_accuracy: 0.6550\n",
      "Epoch 49/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4988 - accuracy: 0.7550 - val_loss: 0.7686 - val_accuracy: 0.6799\n",
      "Epoch 50/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4938 - accuracy: 0.7576 - val_loss: 0.8072 - val_accuracy: 0.6705\n",
      "Epoch 51/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4887 - accuracy: 0.7597 - val_loss: 0.8403 - val_accuracy: 0.6664\n",
      "Epoch 52/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4815 - accuracy: 0.7614 - val_loss: 0.8683 - val_accuracy: 0.6604\n",
      "Epoch 53/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4782 - accuracy: 0.7672 - val_loss: 0.8980 - val_accuracy: 0.6590\n",
      "Epoch 54/100\n",
      "835/835 [==============================] - 1s 991us/step - loss: 0.4713 - accuracy: 0.7695 - val_loss: 0.9228 - val_accuracy: 0.6658\n",
      "Epoch 55/100\n",
      "835/835 [==============================] - 1s 998us/step - loss: 0.4727 - accuracy: 0.7703 - val_loss: 0.9549 - val_accuracy: 0.6523\n",
      "Epoch 56/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4618 - accuracy: 0.7753 - val_loss: 1.0316 - val_accuracy: 0.6644\n",
      "Epoch 57/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4538 - accuracy: 0.7794 - val_loss: 1.0010 - val_accuracy: 0.6496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "835/835 [==============================] - 1s 992us/step - loss: 0.4477 - accuracy: 0.7811 - val_loss: 1.0491 - val_accuracy: 0.6456\n",
      "Epoch 59/100\n",
      "835/835 [==============================] - 1s 999us/step - loss: 0.4505 - accuracy: 0.7829 - val_loss: 1.0726 - val_accuracy: 0.6597\n",
      "Epoch 60/100\n",
      "835/835 [==============================] - 1s 1000us/step - loss: 0.4427 - accuracy: 0.7834 - val_loss: 1.0847 - val_accuracy: 0.6449\n",
      "Epoch 61/100\n",
      "835/835 [==============================] - 1s 986us/step - loss: 0.4325 - accuracy: 0.7898 - val_loss: 1.1756 - val_accuracy: 0.6637\n",
      "Epoch 62/100\n",
      "835/835 [==============================] - 1s 992us/step - loss: 0.4320 - accuracy: 0.7875 - val_loss: 1.2106 - val_accuracy: 0.6442\n",
      "Epoch 63/100\n",
      "835/835 [==============================] - 1s 996us/step - loss: 0.4259 - accuracy: 0.7939 - val_loss: 1.2603 - val_accuracy: 0.6590\n",
      "Epoch 64/100\n",
      "835/835 [==============================] - 1s 991us/step - loss: 0.4202 - accuracy: 0.7993 - val_loss: 1.2638 - val_accuracy: 0.6449\n",
      "Epoch 65/100\n",
      "835/835 [==============================] - 1s 991us/step - loss: 0.4118 - accuracy: 0.8033 - val_loss: 1.2812 - val_accuracy: 0.6590\n",
      "Epoch 66/100\n",
      "835/835 [==============================] - 1s 989us/step - loss: 0.4118 - accuracy: 0.8007 - val_loss: 1.3298 - val_accuracy: 0.6509\n",
      "Epoch 67/100\n",
      "835/835 [==============================] - 1s 995us/step - loss: 0.4110 - accuracy: 0.7999 - val_loss: 1.3155 - val_accuracy: 0.6597\n",
      "Epoch 68/100\n",
      "835/835 [==============================] - 1s 994us/step - loss: 0.4007 - accuracy: 0.8058 - val_loss: 1.4218 - val_accuracy: 0.6631\n",
      "Epoch 69/100\n",
      "835/835 [==============================] - 1s 990us/step - loss: 0.3921 - accuracy: 0.8114 - val_loss: 1.4947 - val_accuracy: 0.6348\n",
      "Epoch 70/100\n",
      "835/835 [==============================] - 1s 999us/step - loss: 0.3905 - accuracy: 0.8122 - val_loss: 1.4484 - val_accuracy: 0.6523\n",
      "Epoch 71/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3897 - accuracy: 0.8142 - val_loss: 1.4145 - val_accuracy: 0.6557\n",
      "Epoch 72/100\n",
      "835/835 [==============================] - 1s 997us/step - loss: 0.3925 - accuracy: 0.8149 - val_loss: 1.4636 - val_accuracy: 0.6550\n",
      "Epoch 73/100\n",
      "835/835 [==============================] - 1s 992us/step - loss: 0.3789 - accuracy: 0.8170 - val_loss: 1.4819 - val_accuracy: 0.6530\n",
      "Epoch 74/100\n",
      "835/835 [==============================] - 1s 994us/step - loss: 0.3737 - accuracy: 0.8183 - val_loss: 1.6201 - val_accuracy: 0.6604\n",
      "Epoch 75/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3731 - accuracy: 0.8206 - val_loss: 1.6564 - val_accuracy: 0.6482\n",
      "Epoch 76/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3615 - accuracy: 0.8248 - val_loss: 1.7497 - val_accuracy: 0.6523\n",
      "Epoch 77/100\n",
      "835/835 [==============================] - 1s 999us/step - loss: 0.3773 - accuracy: 0.8239 - val_loss: 1.7503 - val_accuracy: 0.6402\n",
      "Epoch 78/100\n",
      "835/835 [==============================] - 1s 998us/step - loss: 0.3586 - accuracy: 0.8269 - val_loss: 1.8213 - val_accuracy: 0.6590\n",
      "Epoch 79/100\n",
      "835/835 [==============================] - 1s 986us/step - loss: 0.3635 - accuracy: 0.8293 - val_loss: 1.7075 - val_accuracy: 0.6557\n",
      "Epoch 80/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3487 - accuracy: 0.8356 - val_loss: 1.8991 - val_accuracy: 0.6388\n",
      "Epoch 81/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3506 - accuracy: 0.8335 - val_loss: 2.0195 - val_accuracy: 0.6408\n",
      "Epoch 82/100\n",
      "835/835 [==============================] - 1s 990us/step - loss: 0.3480 - accuracy: 0.8354 - val_loss: 1.9310 - val_accuracy: 0.6449\n",
      "Epoch 83/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3393 - accuracy: 0.8415 - val_loss: 2.1648 - val_accuracy: 0.6496\n",
      "Epoch 84/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3389 - accuracy: 0.8403 - val_loss: 2.0237 - val_accuracy: 0.6476\n",
      "Epoch 85/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3387 - accuracy: 0.8371 - val_loss: 2.1012 - val_accuracy: 0.6348\n",
      "Epoch 86/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3333 - accuracy: 0.8424 - val_loss: 2.1465 - val_accuracy: 0.6429\n",
      "Epoch 87/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3547 - accuracy: 0.8386 - val_loss: 1.9250 - val_accuracy: 0.6375\n",
      "Epoch 88/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3240 - accuracy: 0.8486 - val_loss: 2.1323 - val_accuracy: 0.6361\n",
      "Epoch 89/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3282 - accuracy: 0.8434 - val_loss: 2.0786 - val_accuracy: 0.6395\n",
      "Epoch 90/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3259 - accuracy: 0.8487 - val_loss: 2.2151 - val_accuracy: 0.6395\n",
      "Epoch 91/100\n",
      "835/835 [==============================] - 1s 996us/step - loss: 0.3232 - accuracy: 0.8469 - val_loss: 2.2046 - val_accuracy: 0.6388\n",
      "Epoch 92/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3138 - accuracy: 0.8531 - val_loss: 2.2949 - val_accuracy: 0.6469\n",
      "Epoch 93/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3101 - accuracy: 0.8512 - val_loss: 2.2359 - val_accuracy: 0.6301\n",
      "Epoch 94/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3178 - accuracy: 0.8502 - val_loss: 2.2966 - val_accuracy: 0.6267\n",
      "Epoch 95/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3121 - accuracy: 0.8550 - val_loss: 2.4513 - val_accuracy: 0.6105\n",
      "Epoch 96/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3157 - accuracy: 0.8552 - val_loss: 2.3785 - val_accuracy: 0.6341\n",
      "Epoch 97/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3085 - accuracy: 0.8574 - val_loss: 2.5351 - val_accuracy: 0.6429\n",
      "Epoch 98/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.2983 - accuracy: 0.8574 - val_loss: 2.6274 - val_accuracy: 0.6321\n",
      "Epoch 99/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3021 - accuracy: 0.8603 - val_loss: 2.7518 - val_accuracy: 0.6422\n",
      "Epoch 100/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3048 - accuracy: 0.8547 - val_loss: 2.6772 - val_accuracy: 0.6503\n",
      "Epoch 1/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.7061 - accuracy: 0.7577 - val_loss: 0.5573 - val_accuracy: 0.7837\n",
      "Epoch 2/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5140 - accuracy: 0.7989 - val_loss: 0.5404 - val_accuracy: 0.7857\n",
      "Epoch 3/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5008 - accuracy: 0.7998 - val_loss: 0.5377 - val_accuracy: 0.7857\n",
      "Epoch 4/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4964 - accuracy: 0.8000 - val_loss: 0.5290 - val_accuracy: 0.7871\n",
      "Epoch 5/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4929 - accuracy: 0.8005 - val_loss: 0.5327 - val_accuracy: 0.7871\n",
      "Epoch 6/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4916 - accuracy: 0.7998 - val_loss: 0.5311 - val_accuracy: 0.7871\n",
      "Epoch 7/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4914 - accuracy: 0.8002 - val_loss: 0.5272 - val_accuracy: 0.7877\n",
      "Epoch 8/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4871 - accuracy: 0.8005 - val_loss: 0.5303 - val_accuracy: 0.7871\n",
      "Epoch 9/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4861 - accuracy: 0.8011 - val_loss: 0.5402 - val_accuracy: 0.7857\n",
      "Epoch 10/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4827 - accuracy: 0.8016 - val_loss: 0.5223 - val_accuracy: 0.7850\n",
      "Epoch 11/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4826 - accuracy: 0.8011 - val_loss: 0.5452 - val_accuracy: 0.7871\n",
      "Epoch 12/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4794 - accuracy: 0.8013 - val_loss: 0.5413 - val_accuracy: 0.7864\n",
      "Epoch 13/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4738 - accuracy: 0.8025 - val_loss: 0.5740 - val_accuracy: 0.7837\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4787 - accuracy: 0.8019 - val_loss: 0.5514 - val_accuracy: 0.7871\n",
      "Epoch 15/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4708 - accuracy: 0.8032 - val_loss: 0.5866 - val_accuracy: 0.7803\n",
      "Epoch 16/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4684 - accuracy: 0.8028 - val_loss: 0.5530 - val_accuracy: 0.7864\n",
      "Epoch 17/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4660 - accuracy: 0.8042 - val_loss: 0.5959 - val_accuracy: 0.7790\n",
      "Epoch 18/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4638 - accuracy: 0.8041 - val_loss: 0.6006 - val_accuracy: 0.7857\n",
      "Epoch 19/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4599 - accuracy: 0.8051 - val_loss: 0.6151 - val_accuracy: 0.7837\n",
      "Epoch 20/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4547 - accuracy: 0.8072 - val_loss: 0.5644 - val_accuracy: 0.7823\n",
      "Epoch 21/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4520 - accuracy: 0.8072 - val_loss: 0.6353 - val_accuracy: 0.7796\n",
      "Epoch 22/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4470 - accuracy: 0.8089 - val_loss: 0.6164 - val_accuracy: 0.7763\n",
      "Epoch 23/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4467 - accuracy: 0.8075 - val_loss: 0.6126 - val_accuracy: 0.7844\n",
      "Epoch 24/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4508 - accuracy: 0.8103 - val_loss: 0.6061 - val_accuracy: 0.7823\n",
      "Epoch 25/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4419 - accuracy: 0.8090 - val_loss: 0.6702 - val_accuracy: 0.7770\n",
      "Epoch 26/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4343 - accuracy: 0.8096 - val_loss: 0.6388 - val_accuracy: 0.7796\n",
      "Epoch 27/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4285 - accuracy: 0.8103 - val_loss: 0.7039 - val_accuracy: 0.7790\n",
      "Epoch 28/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4265 - accuracy: 0.8122 - val_loss: 0.6737 - val_accuracy: 0.7763\n",
      "Epoch 29/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4264 - accuracy: 0.8125 - val_loss: 0.6906 - val_accuracy: 0.7810\n",
      "Epoch 30/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4210 - accuracy: 0.8149 - val_loss: 0.7237 - val_accuracy: 0.7749\n",
      "Epoch 31/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4179 - accuracy: 0.8137 - val_loss: 0.7288 - val_accuracy: 0.7668\n",
      "Epoch 32/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4342 - accuracy: 0.8129 - val_loss: 0.7116 - val_accuracy: 0.7783\n",
      "Epoch 33/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4128 - accuracy: 0.8157 - val_loss: 0.7508 - val_accuracy: 0.7763\n",
      "Epoch 34/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4121 - accuracy: 0.8162 - val_loss: 0.7700 - val_accuracy: 0.7709\n",
      "Epoch 35/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4055 - accuracy: 0.8175 - val_loss: 0.7648 - val_accuracy: 0.7749\n",
      "Epoch 36/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4042 - accuracy: 0.8165 - val_loss: 0.7705 - val_accuracy: 0.7695\n",
      "Epoch 37/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4034 - accuracy: 0.8174 - val_loss: 0.7675 - val_accuracy: 0.7648\n",
      "Epoch 38/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4010 - accuracy: 0.8180 - val_loss: 0.8148 - val_accuracy: 0.7702\n",
      "Epoch 39/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3963 - accuracy: 0.8193 - val_loss: 0.8336 - val_accuracy: 0.7796\n",
      "Epoch 40/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3917 - accuracy: 0.8197 - val_loss: 0.8233 - val_accuracy: 0.7743\n",
      "Epoch 41/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3912 - accuracy: 0.8225 - val_loss: 0.8395 - val_accuracy: 0.7716\n",
      "Epoch 42/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3837 - accuracy: 0.8221 - val_loss: 0.8973 - val_accuracy: 0.7776\n",
      "Epoch 43/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3846 - accuracy: 0.8242 - val_loss: 0.9292 - val_accuracy: 0.7642\n",
      "Epoch 44/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3906 - accuracy: 0.8254 - val_loss: 0.8831 - val_accuracy: 0.7487\n",
      "Epoch 45/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3738 - accuracy: 0.8316 - val_loss: 0.8660 - val_accuracy: 0.7615\n",
      "Epoch 46/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3775 - accuracy: 0.8304 - val_loss: 0.9232 - val_accuracy: 0.7500\n",
      "Epoch 47/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3862 - accuracy: 0.8276 - val_loss: 0.9018 - val_accuracy: 0.7540\n",
      "Epoch 48/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3715 - accuracy: 0.8347 - val_loss: 0.9799 - val_accuracy: 0.7554\n",
      "Epoch 49/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3670 - accuracy: 0.8338 - val_loss: 0.9896 - val_accuracy: 0.7574\n",
      "Epoch 50/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3708 - accuracy: 0.8335 - val_loss: 0.9490 - val_accuracy: 0.7500\n",
      "Epoch 51/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3630 - accuracy: 0.8368 - val_loss: 0.9483 - val_accuracy: 0.7487\n",
      "Epoch 52/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3659 - accuracy: 0.8364 - val_loss: 0.9760 - val_accuracy: 0.7520\n",
      "Epoch 53/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3545 - accuracy: 0.8398 - val_loss: 0.9371 - val_accuracy: 0.7561\n",
      "Epoch 54/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3532 - accuracy: 0.8401 - val_loss: 1.0453 - val_accuracy: 0.7385\n",
      "Epoch 55/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3662 - accuracy: 0.8401 - val_loss: 1.0352 - val_accuracy: 0.7487\n",
      "Epoch 56/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3478 - accuracy: 0.8437 - val_loss: 1.0199 - val_accuracy: 0.7527\n",
      "Epoch 57/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3579 - accuracy: 0.8437 - val_loss: 1.0565 - val_accuracy: 0.7527\n",
      "Epoch 58/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3478 - accuracy: 0.8442 - val_loss: 0.9765 - val_accuracy: 0.7345\n",
      "Epoch 59/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3460 - accuracy: 0.8448 - val_loss: 0.9657 - val_accuracy: 0.7406\n",
      "Epoch 60/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3374 - accuracy: 0.8469 - val_loss: 1.1568 - val_accuracy: 0.7480\n",
      "Epoch 61/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3367 - accuracy: 0.8475 - val_loss: 1.1942 - val_accuracy: 0.7493\n",
      "Epoch 62/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3430 - accuracy: 0.8426 - val_loss: 1.0692 - val_accuracy: 0.7305\n",
      "Epoch 63/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3319 - accuracy: 0.8518 - val_loss: 1.1247 - val_accuracy: 0.7392\n",
      "Epoch 64/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3373 - accuracy: 0.8484 - val_loss: 1.2462 - val_accuracy: 0.7372\n",
      "Epoch 65/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3273 - accuracy: 0.8515 - val_loss: 1.2298 - val_accuracy: 0.7412\n",
      "Epoch 66/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3251 - accuracy: 0.8528 - val_loss: 1.3053 - val_accuracy: 0.7520\n",
      "Epoch 67/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3280 - accuracy: 0.8537 - val_loss: 1.2538 - val_accuracy: 0.7399\n",
      "Epoch 68/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3254 - accuracy: 0.8533 - val_loss: 1.3396 - val_accuracy: 0.7345\n",
      "Epoch 69/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3189 - accuracy: 0.8557 - val_loss: 1.2653 - val_accuracy: 0.7345\n",
      "Epoch 70/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3300 - accuracy: 0.8533 - val_loss: 1.3714 - val_accuracy: 0.7224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3218 - accuracy: 0.8582 - val_loss: 1.3023 - val_accuracy: 0.7406\n",
      "Epoch 72/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3224 - accuracy: 0.8535 - val_loss: 1.2804 - val_accuracy: 0.7358\n",
      "Epoch 73/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3159 - accuracy: 0.8570 - val_loss: 1.4025 - val_accuracy: 0.7379\n",
      "Epoch 74/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3087 - accuracy: 0.8602 - val_loss: 1.4079 - val_accuracy: 0.7439\n",
      "Epoch 75/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3121 - accuracy: 0.8605 - val_loss: 1.2685 - val_accuracy: 0.7345\n",
      "Epoch 76/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3198 - accuracy: 0.8605 - val_loss: 1.4139 - val_accuracy: 0.7412\n",
      "Epoch 77/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3017 - accuracy: 0.8638 - val_loss: 1.3578 - val_accuracy: 0.7311\n",
      "Epoch 78/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3022 - accuracy: 0.8663 - val_loss: 1.3221 - val_accuracy: 0.7439\n",
      "Epoch 79/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3119 - accuracy: 0.8612 - val_loss: 1.2485 - val_accuracy: 0.7116\n",
      "Epoch 80/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3069 - accuracy: 0.8635 - val_loss: 1.4552 - val_accuracy: 0.7433\n",
      "Epoch 81/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3025 - accuracy: 0.8628 - val_loss: 1.4021 - val_accuracy: 0.7412\n",
      "Epoch 82/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3127 - accuracy: 0.8614 - val_loss: 1.3786 - val_accuracy: 0.7257\n",
      "Epoch 83/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.2971 - accuracy: 0.8648 - val_loss: 1.4427 - val_accuracy: 0.7352\n",
      "Epoch 84/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3062 - accuracy: 0.8649 - val_loss: 1.3072 - val_accuracy: 0.7257\n",
      "Epoch 85/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.2972 - accuracy: 0.8666 - val_loss: 1.4661 - val_accuracy: 0.7204\n",
      "Epoch 86/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3052 - accuracy: 0.8620 - val_loss: 1.4976 - val_accuracy: 0.7338\n",
      "Epoch 87/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.2896 - accuracy: 0.8702 - val_loss: 1.4678 - val_accuracy: 0.7338\n",
      "Epoch 88/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.2933 - accuracy: 0.8690 - val_loss: 1.5086 - val_accuracy: 0.7123\n",
      "Epoch 89/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.2891 - accuracy: 0.8718 - val_loss: 1.4763 - val_accuracy: 0.7136\n",
      "Epoch 90/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.2904 - accuracy: 0.8710 - val_loss: 1.4795 - val_accuracy: 0.7156\n",
      "Epoch 91/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.2839 - accuracy: 0.8728 - val_loss: 1.4668 - val_accuracy: 0.7150\n",
      "Epoch 92/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.2994 - accuracy: 0.8681 - val_loss: 1.5290 - val_accuracy: 0.7284\n",
      "Epoch 93/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.2755 - accuracy: 0.8754 - val_loss: 1.6824 - val_accuracy: 0.7109\n",
      "Epoch 94/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.2835 - accuracy: 0.8755 - val_loss: 1.5486 - val_accuracy: 0.7089\n",
      "Epoch 95/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.3004 - accuracy: 0.8663 - val_loss: 1.6795 - val_accuracy: 0.7284\n",
      "Epoch 96/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.2743 - accuracy: 0.8803 - val_loss: 1.6863 - val_accuracy: 0.7332\n",
      "Epoch 97/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.2807 - accuracy: 0.8739 - val_loss: 1.4983 - val_accuracy: 0.7237\n",
      "Epoch 98/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.2834 - accuracy: 0.8743 - val_loss: 1.4857 - val_accuracy: 0.7244\n",
      "Epoch 99/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.2765 - accuracy: 0.8780 - val_loss: 1.5812 - val_accuracy: 0.7028\n",
      "Epoch 100/100\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.2703 - accuracy: 0.8791 - val_loss: 1.7182 - val_accuracy: 0.7237\n",
      "310/310 [==============================] - 0s 465us/step\n",
      "310/310 [==============================] - 0s 458us/step\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(64, 3, activation='relu', input_shape=(31,1)))  \n",
    "model.add(MaxPooling1D(2))  \n",
    "model.add(Conv1D(64, 3, activation='relu')) \n",
    "model.add(MaxPooling1D(2))  \n",
    "model.add(Flatten()) \n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid')) \n",
    "\n",
    "model1 = model2 = model\n",
    "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model1.fit(X_train, EC1_train, epochs=100, batch_size=16, validation_split=0.1)\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model2.fit(X_train, EC2_train, epochs=100, batch_size=16, validation_split=0.1)\n",
    "EC1_pred = model1.predict(X_test)\n",
    "EC2_pred = model2.predict(X_test)\n",
    "\n",
    "df_samp['EC1'] = EC1_pred\n",
    "df_samp['EC2'] = EC2_pred\n",
    "\n",
    "df_samp.to_csv('submission3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "49b53d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.7210 - accuracy: 0.6575 - val_loss: 0.6258 - val_accuracy: 0.6792\n",
      "Epoch 2/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.6009 - accuracy: 0.6789 - val_loss: 0.6150 - val_accuracy: 0.6813\n",
      "Epoch 3/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5942 - accuracy: 0.6844 - val_loss: 0.6048 - val_accuracy: 0.6786\n",
      "Epoch 4/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5931 - accuracy: 0.6852 - val_loss: 0.6023 - val_accuracy: 0.6678\n",
      "Epoch 5/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5855 - accuracy: 0.6920 - val_loss: 0.5987 - val_accuracy: 0.6846\n",
      "Epoch 6/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5846 - accuracy: 0.6918 - val_loss: 0.6047 - val_accuracy: 0.6799\n",
      "Epoch 7/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5829 - accuracy: 0.6956 - val_loss: 0.5999 - val_accuracy: 0.6873\n",
      "Epoch 8/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5825 - accuracy: 0.7016 - val_loss: 0.5974 - val_accuracy: 0.6786\n",
      "Epoch 9/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5816 - accuracy: 0.6978 - val_loss: 0.5987 - val_accuracy: 0.6900\n",
      "Epoch 10/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5815 - accuracy: 0.6966 - val_loss: 0.5961 - val_accuracy: 0.6873\n",
      "Epoch 11/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5806 - accuracy: 0.6978 - val_loss: 0.6012 - val_accuracy: 0.6887\n",
      "Epoch 12/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5801 - accuracy: 0.7020 - val_loss: 0.6062 - val_accuracy: 0.6698\n",
      "Epoch 13/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5789 - accuracy: 0.7003 - val_loss: 0.5981 - val_accuracy: 0.6860\n",
      "Epoch 14/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5774 - accuracy: 0.7037 - val_loss: 0.5993 - val_accuracy: 0.6819\n",
      "Epoch 15/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5784 - accuracy: 0.7023 - val_loss: 0.6069 - val_accuracy: 0.6900\n",
      "Epoch 16/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5779 - accuracy: 0.7038 - val_loss: 0.5955 - val_accuracy: 0.6907\n",
      "Epoch 17/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5772 - accuracy: 0.7020 - val_loss: 0.6002 - val_accuracy: 0.6907\n",
      "Epoch 18/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5754 - accuracy: 0.7046 - val_loss: 0.6015 - val_accuracy: 0.6995\n",
      "Epoch 19/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5739 - accuracy: 0.7048 - val_loss: 0.5989 - val_accuracy: 0.6947\n",
      "Epoch 20/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5734 - accuracy: 0.7038 - val_loss: 0.6049 - val_accuracy: 0.6887\n",
      "Epoch 21/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5713 - accuracy: 0.7048 - val_loss: 0.6071 - val_accuracy: 0.6947\n",
      "Epoch 22/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5705 - accuracy: 0.7076 - val_loss: 0.6084 - val_accuracy: 0.6880\n",
      "Epoch 23/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5706 - accuracy: 0.7059 - val_loss: 0.5970 - val_accuracy: 0.6934\n",
      "Epoch 24/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5682 - accuracy: 0.7065 - val_loss: 0.6077 - val_accuracy: 0.6947\n",
      "Epoch 25/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5677 - accuracy: 0.7087 - val_loss: 0.6152 - val_accuracy: 0.6894\n",
      "Epoch 26/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5669 - accuracy: 0.7071 - val_loss: 0.6265 - val_accuracy: 0.6887\n",
      "Epoch 27/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5661 - accuracy: 0.7099 - val_loss: 0.6177 - val_accuracy: 0.6826\n",
      "Epoch 28/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5637 - accuracy: 0.7106 - val_loss: 0.6130 - val_accuracy: 0.6907\n",
      "Epoch 29/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5623 - accuracy: 0.7116 - val_loss: 0.6163 - val_accuracy: 0.6934\n",
      "Epoch 30/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5610 - accuracy: 0.7110 - val_loss: 0.6184 - val_accuracy: 0.6914\n",
      "Epoch 31/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5584 - accuracy: 0.7093 - val_loss: 0.6253 - val_accuracy: 0.6819\n",
      "Epoch 32/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5569 - accuracy: 0.7143 - val_loss: 0.6192 - val_accuracy: 0.6907\n",
      "Epoch 33/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5566 - accuracy: 0.7156 - val_loss: 0.6320 - val_accuracy: 0.6840\n",
      "Epoch 34/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5551 - accuracy: 0.7145 - val_loss: 0.6262 - val_accuracy: 0.6840\n",
      "Epoch 35/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5528 - accuracy: 0.7169 - val_loss: 0.6280 - val_accuracy: 0.6927\n",
      "Epoch 1/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.5186 - accuracy: 0.7974 - val_loss: 0.5165 - val_accuracy: 0.7871\n",
      "Epoch 2/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4995 - accuracy: 0.8003 - val_loss: 0.5146 - val_accuracy: 0.7864\n",
      "Epoch 3/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4972 - accuracy: 0.8001 - val_loss: 0.5176 - val_accuracy: 0.7871\n",
      "Epoch 4/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4945 - accuracy: 0.8003 - val_loss: 0.5170 - val_accuracy: 0.7871\n",
      "Epoch 5/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4945 - accuracy: 0.8003 - val_loss: 0.5258 - val_accuracy: 0.7871\n",
      "Epoch 6/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4926 - accuracy: 0.8003 - val_loss: 0.5230 - val_accuracy: 0.7871\n",
      "Epoch 7/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4935 - accuracy: 0.8003 - val_loss: 0.5171 - val_accuracy: 0.7871\n",
      "Epoch 8/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4912 - accuracy: 0.8004 - val_loss: 0.5160 - val_accuracy: 0.7871\n",
      "Epoch 9/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4912 - accuracy: 0.8002 - val_loss: 0.5436 - val_accuracy: 0.7871\n",
      "Epoch 10/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4931 - accuracy: 0.8003 - val_loss: 0.5168 - val_accuracy: 0.7871\n",
      "Epoch 11/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4907 - accuracy: 0.8003 - val_loss: 0.5162 - val_accuracy: 0.7871\n",
      "Epoch 12/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4895 - accuracy: 0.8003 - val_loss: 0.5195 - val_accuracy: 0.7871\n",
      "Epoch 13/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4900 - accuracy: 0.8002 - val_loss: 0.5140 - val_accuracy: 0.7871\n",
      "Epoch 14/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4882 - accuracy: 0.8002 - val_loss: 0.5173 - val_accuracy: 0.7871\n",
      "Epoch 15/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4885 - accuracy: 0.8001 - val_loss: 0.5152 - val_accuracy: 0.7871\n",
      "Epoch 16/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4875 - accuracy: 0.8004 - val_loss: 0.5198 - val_accuracy: 0.7871\n",
      "Epoch 17/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4862 - accuracy: 0.8004 - val_loss: 0.5227 - val_accuracy: 0.7871\n",
      "Epoch 18/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4845 - accuracy: 0.8003 - val_loss: 0.5246 - val_accuracy: 0.7871\n",
      "Epoch 19/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4851 - accuracy: 0.8000 - val_loss: 0.5208 - val_accuracy: 0.7871\n",
      "Epoch 20/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4837 - accuracy: 0.8005 - val_loss: 0.5309 - val_accuracy: 0.7871\n",
      "Epoch 21/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4823 - accuracy: 0.8008 - val_loss: 0.5225 - val_accuracy: 0.7871\n",
      "Epoch 22/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4810 - accuracy: 0.8003 - val_loss: 0.5205 - val_accuracy: 0.7877\n",
      "Epoch 23/35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4766 - accuracy: 0.8013 - val_loss: 0.5280 - val_accuracy: 0.7864\n",
      "Epoch 24/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4773 - accuracy: 0.8018 - val_loss: 0.5285 - val_accuracy: 0.7871\n",
      "Epoch 25/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4750 - accuracy: 0.8015 - val_loss: 0.5350 - val_accuracy: 0.7864\n",
      "Epoch 26/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4728 - accuracy: 0.8019 - val_loss: 0.5357 - val_accuracy: 0.7844\n",
      "Epoch 27/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4715 - accuracy: 0.8028 - val_loss: 0.5378 - val_accuracy: 0.7830\n",
      "Epoch 28/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4712 - accuracy: 0.8015 - val_loss: 0.5386 - val_accuracy: 0.7864\n",
      "Epoch 29/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4683 - accuracy: 0.8019 - val_loss: 0.5443 - val_accuracy: 0.7830\n",
      "Epoch 30/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4673 - accuracy: 0.8027 - val_loss: 0.5369 - val_accuracy: 0.7803\n",
      "Epoch 31/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4623 - accuracy: 0.8048 - val_loss: 0.5529 - val_accuracy: 0.7803\n",
      "Epoch 32/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4608 - accuracy: 0.8031 - val_loss: 0.5586 - val_accuracy: 0.7776\n",
      "Epoch 33/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4582 - accuracy: 0.8040 - val_loss: 0.5510 - val_accuracy: 0.7817\n",
      "Epoch 34/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4570 - accuracy: 0.8057 - val_loss: 0.5636 - val_accuracy: 0.7810\n",
      "Epoch 35/35\n",
      "835/835 [==============================] - 1s 1ms/step - loss: 0.4543 - accuracy: 0.8073 - val_loss: 0.5763 - val_accuracy: 0.7655\n",
      "310/310 [==============================] - 0s 461us/step\n",
      "310/310 [==============================] - 0s 460us/step\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(64, 3, activation='relu', input_shape=(31,1)))  \n",
    "model.add(MaxPooling1D(2))  \n",
    "model.add(Conv1D(64, 3, activation='relu')) \n",
    "model.add(MaxPooling1D(2))  \n",
    "model.add(Flatten()) \n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid')) \n",
    "\n",
    "model1 = model2 = model\n",
    "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model1.fit(X_train, EC1_train, epochs=35, batch_size=16, validation_split=0.1)\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model2.fit(X_train, EC2_train, epochs=35, batch_size=16, validation_split=0.1)\n",
    "EC1_pred = model1.predict(X_test)\n",
    "EC2_pred = model2.predict(X_test)\n",
    "\n",
    "df_samp['EC1'] = EC1_pred\n",
    "df_samp['EC2'] = EC2_pred\n",
    "\n",
    "df_samp.to_csv('submission4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e760d7a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
